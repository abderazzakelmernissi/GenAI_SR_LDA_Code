Generative AI in student English learning in Thai higher education: More engagement, better outcomes?
Despite the growing body of research exploring artificial intelligence (AI) in educational contexts, there remains a critical gap in understanding the specific effects of generative AI (GAI) on English language learning, particularly within higher education in Thailand. This study addresses this gap by employing an explanatory sequential mixed-method design to explore both student and teacher perspectives. Quantitative data were analyzed using descriptive statistics, Mann-Whitney U tests, Spearman correlation analysis, and Kendall–Theil regression to examine students' acceptance, usage, and the relationship between GAI engagement and academic performance. Qualitative data, collected through structured written interviews, were analyzed using thematic analysis to uncover key themes from both student and teacher narratives. Quantitative findings reveal high student acceptance of GAI tools in terms of performance expectancy (M = 3.66, SD = .58), effort expectancy (M = 3.61, SD = .59), facilitating conditions (M = 3.51, SD = .59), and use behavior (M = 3.52, SD = .48), while social influence remained relatively lower (M = 3.31, SD = .54). Mann-Whitney U tests showed no statistically significant differences in GAI usage across high- and low-performing students (p > .05). Correlation analyses indicated strong associations between performance expectancy and other factors (ρ = .87, p < .001), yet no significant correlation with GPA (ρ = −.06, p = .76). Qualitative results from student reflections revealed improved efficiency, enhanced engagement, and increased linguistic confidence. Yet, concerns about overreliance on AI and the necessity for critical use were noted. Teacher narratives accentuated ethical concerns and the potential for GAI misuse, highlighting the need for balanced, responsible integration of AI into pedagogical practices. These findings underscore the potential of GAI to enhance learning experiences while emphasizing the importance of maintaining academic integrity and fostering critical thinking.

Keywords
Generative AI Student acceptance English learning Thai higher education

1. Introduction
While there has been a notable surge in studies exploring the potential integration of Generative Artificial Intelligence (GAI) into pedagogical practices within higher education (Farrelly & Baker, 2023), a critical gap persists in comprehensively assessing the impact of GAI on student English learning, involving students and teachers’ narratives. At the university level, GAI applications such as language models and intelligent tutoring systems have assumed pivotal roles, offering learners adaptive feedback and fostering immersive, context-rich learning environments (Barrett & Pack, 2023; Chiu, 2024). Prior research has thoroughly examined the role of technology in language learning, particularly through computer-assisted language learning (CALL) and mobile-assisted language learning (MALL), highlighting how these technologies enhance language learning by improving learner interaction, engagement, and access to authentic language contexts (Anggoro & Pratiwi, 2023; Liu et al., 2024; Yang et al., 2022; Zadorozhnyy & Lai, 2023).
Existing literature offers general insights into the use of artificial intelligence (AI) in educational settings but lacks specificity regarding the impacts of Generative AI (GAI) technologies on English language learning, particularly within the Thai higher education context. Studies such as those by Kohnke et al. (2023) and Moorhouse et al. (2023) have begun to explore AI applications broadly, yet there remains a significant gap in focused research examining how GAI technologies are perceived and accepted by students, as well as their specific effects on language learning outcomes. Moreover, the perspectives of English lecturers—who are instrumental in integrating these technologies into educational curricula—are often overlooked. Understanding how these educators adapt their teaching strategies, engage students, and perceive the outcomes of using GAI is crucial for a comprehensive assessment of AI's educational potential and limitations.
This study aims to address these gaps by conducting a detailed investigation of the impacts of generative AI on English language learning in Thai higher education. It centers on three primary objectives: firstly, to investigate how students perceive and accept the use of generative AI in their English language learning; secondly, to evaluate the effects of GAI applications on student learning outcomes, assessing their performance before and after the introduction of these technologies; and thirdly, to gather and analyze the experiences of English lecturers with regard to the integration of GAI in their teaching practices. This approach seeks to provide a holistic understanding of the role and effectiveness of generative AI in enhancing English language education in Thailand. The following research questions are addressed.
1)
How do students perceive and accept the use of generative AI in their English learning within higher education?
2)
What are the effects of generative AI applications on student English learning both before and after the emergence of these technologies?
3)
Drawing from their teaching experiences, how do English lecturers observe the impacts of generative AI applications on their students' English learning?
2. Literature review
2.1. The emergence of generative AI (GAI) and English teaching and learning
The inception of Artificial Intelligence (AI) in 1956 marked a seminal moment in technological history, epitomized by Newell and Simon's development of the ‘thinking machine’ program, which sought to emulate human cognitive abilities to solve intricate problems (McCarthy, 2007; Newell & Simon, 1956). This breakthrough paved the way for the emergence of AI in Education (AIED), a field dedicated to harnessing AI technologies to revolutionize teaching, learning, and decision-making processes. Through the creation of intelligent tutoring systems, adaptive learning tools, and sophisticated advisory platforms, AIED aims to offer personalized educational experiences, thereby enhancing the efficacy of learning interventions (Chiu et al., 2023). These innovations are not merely technological advancements but represent a paradigm shift towards more inclusive, adaptive, and responsive educational practices. Nonetheless, the integration of AI in education necessitates a critical examination of ethical considerations, data privacy, and the potential reinforcement of existing inequalities. As the field of AIED continues to evolve, it is crucial that its development is underpinned by a commitment to equity, inclusivity, and learner autonomy, thereby ensuring that AI serves as a catalyst for transformative educational practices.
The integration of GAI into the field of English language education has catalyzed an academic exploration into how both educators and learners adapt to and perceive this technological advancement. Investigations by Kohnke et al. (2023) and Moorhouse (2024) specifically examined the readiness of language faculty at Hong Kong universities to adopt GAI tools within their instructional strategies. These studies illuminate a pivotal relationship between the educators' proficiency and comfort with GAI technologies and the obstacles and apprehensions they encounter in adoption efforts. The findings articulate a pressing need for customized institutional support and ongoing professional development to enhance faculty capabilities in utilizing GAI, a support system that is notably absent across the range of global higher education institutions (Moorhouse et al., 2023). Moreover, research within Vietnamese and Saudi Arabian academic contexts has revealed a reluctance among faculty to integrate GAI tools into their teaching, largely due to a lack of familiarity with these technologies and concerns over academic integrity (Alammari, 2024; Cong-Lem et al., 2024).
Nevertheless, from the perspective of student engagement with GAI, previous studies have delved into various innovative uses of GAI, each tailored to different aspects of language learning. As an example, Wan and Moorhouse (2024) documented the use of the tool Call Annie to enhance conversational practice, offering students a virtual environment to refine their speaking skills through interactive dialogues. Correspondingly, Wan and Moorhouse (2023) have leveraged ChatGPT to enhance written communicative abilities by providing real-time feedback and generating writing prompts that challenge students' language use, thereby fostering improvement in written expression and comprehension. Anggoro and Pratiwi (2023) observed that Quizizz AI encourages learners to take charge of their educational journey by adapting quizzes to their learning pace and proficiency level. Lastly, Liu et al. (2024) looked into the use of AI-facilitated digital multimodal compositions, which combine different types of media to improve cognitive engagement. This helps students understand language better and remember it longer. These diverse implementations not only highlight GAI's versatility in adapting to educational needs, but also its potential to transform traditional learning paradigms by introducing more personalized, engaging, and responsive educational experiences in the realm of language learning.
Moreover, GAI has the potential to foster critical thinking skills among language learners, a process essential to language education as it encourages learners to analyze, evaluate, and synthesize information (Halim et al., 2023). GAI tools support this by presenting learners with complex language tasks that require higher-order cognitive skills. For instance, ChatGPT can generate prompts that challenge students to engage in critical discussions or produce written responses that reflect their understanding of nuanced language concepts (Tran & Tran, 2023). This capability not only enhances language proficiency but also prepares students for real-world communication scenarios where critical thinking is paramount. Yet, integrating GAI in English language learning presents challenges, particularly concerning academic integrity and the originality of student work. Hutson (2024) discusses the implications of GAI on research originality, suggesting that reliance on AI-generated content may undermine students' ability to produce authentic work. This concern is echoed by Alasadi and Baiz (2023), who argue that while GAI can facilitate learning, it may also lead to superficial engagement with language tasks if students rely too heavily on AI for content generation. Therefore, educators must maintain a balance between leveraging GAI for support and ensuring that students actively engage with the language learning process.
2.2. Student acceptance of generative AI
One of the focal points identified in prior research in assessing the impacts of GAI on student learning within higher education pertains to the aspect of student acceptance. Examining this aspect is pivotal as it enables educators to customize instructional approaches to suit students' preferences, effectively integrate cutting-edge technologies to enrich language teaching, foster critical thinking abilities by assessing the utility of AI tools, address ethical concerns to ensure a secure learning environment, and equip students for success in both academic and professional aspects in an increasingly digitized society (Abdaljaleel et al., 2024; Yilmaz et al., 2023). This aspect has been probed through the analysis of students' behavioral intentions, serving as a gateway to understanding their utilization of GAI within the context of higher education learning processes.
Across diverse geographical contexts, empirical studies offer multifaceted insights into the determinants of student acceptance of GAI. In Ghana, Salifu et al. (2024) conducted a survey involving 306 undergraduate respondents, revealing that factors such as social influence, performance expectancy, hedonic motivation, and habits play pivotal roles in driving students' behavioral intentions, which subsequently influence their actual utilization of GAI. In contrast, findings from Jordan, as reported by Masadeh et al. (2024) based on data collected from 880 students, emphasize the significance of credibility, usefulness, and ease of use in shaping students' positive attitudes towards GAI adoption in classroom settings. Especially, student attitude mediates the relationship between perceived usefulness and intention to use GAI. Similarly, research in Bangladesh by Rahman et al. (2022), involving 344 students from private and public universities, underlines the importance of perceived usefulness, perceived ease of use, and perceived informativeness in shaping students' attitudes towards GAI for learning, subsequently influencing their behavioral intention to use it.
In Sri Lanka, Sabraz Nawaz et al. (2024) surveyed 500 undergraduates across 17 government universities, highlighting the impact of habit, performance expectancy, and perceived ease of use on students' acceptance of AI applications. Their findings emphasize the necessity for effective implementation strategies, recognition of individual differences in technology adoption, and ongoing support and training to enhance students' proficiency. Conversely, in Malaysia, Foroughi et al. (2023)employed a hybrid analytical approach with data collected from 406 students. Their study revealed that performance expectancy, effort expectancy, hedonic motivation, and learning value significantly influence the intention to use GAI, while social influence, facilitating conditions, and habit do not exert a significant effect on GAI utilization. Meanwhile, Teerawongsathorn's (2023) study in Bangkok, Thailand, involving 400 participants, revealed that perceived usefulness, perceived ease of use, attitudes toward usage, and behavioral intentions significantly and positively correlate with the actual usage of GAI.
These comparative findings elucidate the diverse factors shaping student acceptance of GAI across different national and institutional contexts, emphasizing the need for tailored approaches to foster effective integration and utilization of AI technologies in education. Nevertheless, there remains a dearth of understanding regarding English as a Foreign Language (EFL) students' acceptance of Generative Artificial Intelligence (GAI) concerning their behavioral intentions and usage behavior in English learning contexts. Moreover, our comprehension is limited regarding disparities between low and high-performing EFL students in this area of inquiry. Therefore, the first research question of this study aims to address this gap in knowledge.
2.3. Impacts of generative AI (GAI) in English learning
The impacts of GAI on student English learning are multifaceted and evolving, representing both opportunities and challenges in educational settings. One significant impact lies in personalized learning experiences. GAI applications can analyze individual student strengths, weaknesses, and learning styles, enabling educators to tailor instruction and provide targeted support, thereby enhancing student engagement and academic outcomes. Examples of this include the use of Quizizz AI for promoting self-directed learning assessments (Anggoro & Pratiwi, 2023) and AI chatbot an English conversation partner in EFL speaking classes (Yang et al., 2022). These GAI applications offer immediate feedback and adaptive learning pathways, fostering self-directed learning and student autonomy. Moreover, GAI facilitates language practice and communication opportunities through conversational agents and language learning applications, promoting immersive language experiences beyond the classroom. Among the applications are Call Annie for conversational practice (Wan & Moorhouse, 2024) and ChatGPT for advancing written communicative abilities (Zadorozhnyy & Lai, 2023).
Recent research stresses teachers' awareness of students' utilization of Generative Artificial Intelligence (GAI) and their recognition of its potential benefits. Through qualitative interviews with Indonesian EFL lecturers, Marzuki et al. (2023) unveiled unanimous agreement among educators regarding the positive effects of AI writing tools on students' writing quality, particularly in terms of content and organizational improvements. Similarly, both EFL students and teachers in the United States acknowledged the acceptable use of GenAI tools in the writing process, while highlighting the pressing need for explicit guidelines and professional development for educators in leveraging GenAI effectively within educational contexts (Barrett & Pack, 2023). While EFL instructors in Hong Kong expressed confidence in the advantages of GAI usage (Kohnke et al., 2023), Kaplan-Rakowski et al. (2023) cautioned against if teachers' positive perspectives invariably translate into action. The integration of GAI in English learning presents a complex array of both positive and negative impacts. Thus, the second and third research inquiries of the current study aim to delve into both students' and teachers' narratives regarding the influence of GAI on English learning outcomes in higher education.
3. Method
3.1. Research Design
To answer the research questions, this study adopted an explanatory sequential mixed-method research design, enabling researchers to integrate both quantitative and qualitative data collection methods (Bowen et al., 2017). Fig. 1 below illustrates the research design.
Fig. 1
Download: Download high-res image (652KB)
Download: Download full-size image
Fig. 1. Illustration of the research design.

3.2. Research setting
The research was carried out within the English Department of an autonomous university in southern Thailand using a convenience sampling method (Sedgwick, 2013), with a specific focus on 25 third-year students aged between 20 and 22 years old (M = 2.56, SD = .58). Among the participants, 23 were female (92%), and 2 was male (8%). Their language proficiency spanned from A2 to B1 in the Common European Framework of Reference (CEFR). These students, aspiring to become teachers, specialized in the teaching track modules, including Introduction to EFL Pedagogy, Language Acquisition, and Curriculum and Course Development. These individuals had previously undergone English learning in higher education without the integration of AI during their first year. The introduction and subsequent widespread adoption of generative AI writing apps, such as Grammarly, Quillbot, ChatGPT, Bard, BingChat, and Reverso, in their second year marked a pivotal transformation in their learning environment. This transition from traditional methods to AI-infused education provided a unique context to explore how emerging technologies influenced the academic journey of these students in terms of English learning.
This also research engaged three English lecturers, who previously taught this group of students: one from Indonesia with a master's degree and three years of teaching experience, and two from Thailand with doctoral degrees and over seven years of teaching experience each at the university. Their insights, spanning teaching periods before and after the introduction of generative AI, offer valuable perspectives on the impact of AI on student English learning in higher education.
3.3. Instruments and measures
3.3.1. Survey: acceptance scale
Students participated in an online survey aimed at gauging their acceptance of generative AI applications. The Likert scale utilized in the survey, adapted from Yilmaz et al. (2023), ranged from 1 (indicating strong disagreement) to 5 (indicating strong agreement). Comprising 18 items, the survey was categorized into four sub-scales: Performance Expectancy (7 items), Effort Expectancy (4 items), Facilitating Conditions (3 items), and Social Influence (4 items). These sub-scales collectively measured students' behavior regarding the use of generative AI.
To ensure the survey's validity, all items underwent face validity assessment by an expert in English Language Teaching, renowned for research at the intersection of ELT and Technology. Subsequently, the researchers evaluated the internal consistency of both the sub-scales and the overall scale. The findings revealed high internal consistency, with Cronbach's alpha exceeding .70 for all sub-scales except Social Influence. However, as seen in Table 1, given the strong internal consistency of the entire scale (α = .91), researchers opted to retain it in the analysis.
Table 1. Construct and internal reliability results.

Empty Cell	Constructs and Sample Statements	α
Sub-Scales	1. Performance Expectancy	.85
E.g., The use of generative AI writing applications makes it easier to do my assignments.	
2. Effort Expectancy	.84
E.g., It is easy for me to become skilled in using generative AI writing applications.	
3. Facilitating Condition	.75
E.g., I can get help from others when I have difficulties in using generative AI writing applications.	
4. Social Influence	.5
E.g., I am influenced by my peers' recommendations in using generative AI writing apps for studying.	
Scale	5. Use Behavior	.91
Following Stapleton's (1997) recommendation, Exploratory Factor Analysis (EFA) was utilized to validate the questionnaire. The KMO and Bartlett's tests yielded significant results: (χ2 (153) = 341.542, p < 001), with a sampling adequacy of .599, surpassing the accepted threshold of .50. These outcomes confirm that the survey constructs effectively capture the intended information. Moreover, all data exhibited normal distribution, with neither skewness nor Kurtosis values exceeding +2 or −2 (Mallery & George, 2000). These findings justify the continued utilization of survey data in subsequent data analysis stages employing parametric tests.
3.3.2. Written interviews
Structured written interviews were conducted to explore both students and lecturers' narratives. This method was selected to avoid misunderstanding between researchers and participants due to language barriers and considered effective given the students and lecturers’ busy schedules, following the protocols recommended by Jacob and Furgerson (2012). The written interviews were done in 15–20 min via Google Form comprising of two questions for both student and teacher participants. For students, they were prompted to reflect on their English language learning experiences both before and after the introduction of AI applications. Secondly, they were instructed to compare the methods and skills used in each situation and discuss any new capabilities or improvements in their language learning journey facilitated using AI apps. As for teachers, the first question is about their observations of how students use generative AI writing applications, with a request for detailed explanations and specific examples. Additionally, teachers were asked to share their opinions on how these applications impact their students' English learning experiences, drawing comparisons between the periods before and after the introduction of AI technologies. These reflective essays aimed to capture a deeper understanding of the practical implications and pedagogical perspectives surrounding the integration of generative AI in English education. Students were coded with S1, S2, S3, etc. And teachers were coded with T1, T2, and T3.
3.3.3. Learning outcomes: students’ GPAs
The assessment of learning outcomes involved the collection of students' Grade Point Averages (GPAs) by researchers. This metric was deemed appropriate given that students' GPAs were derived from their enrollment in diverse English courses both prior to and following the introduction of artificial intelligence (AI). The range of GPAs observed ranged from a minimum of 2.15 to a maximum of 3.79, with a mean GPA of 2.85 and a standard deviation of .47.
3.3.4. Data collection
This study adopts a sequential research design, wherein the quantitative phase precedes the qualitative phase. The first phase of the data collection was initiated through the survey to students using Google Forms, conveniently shared via QR codes, within a class instructed by one of the researchers. All participating students were thoroughly briefed on the study's confidentiality measures and required to confirm their consent. To ensure their confidentiality, no personal identifiers, such as names, Student IDs, or emails were collected without explicit consent. Phase two took place in the following week, where students engaged in reflective written interviews. Concurrently, teachers were invited to share their perspectives through a personally distributed Google Form. Phase three involved a meticulous data cleaning and preparation process to ensure the completeness and accuracy before being triangulated with the qualitative data to contextualize the quantitative findings.
3.3.5. Data analysis
First, students’ survey responses were categorized into three: 0–1.7 = low, 1.8–3.4 = moderate, and 3.5–5.0 = high for descriptive statistics. Then, students were divided into two groups: low (GPAs <3.0) and high (GPAs >3.0) performing students for Mann Whitney U tests. Afterwards, Spearman correlations and Kendall–Theil regression were performed. All these were used to answer the first question. Then, thematic analysis as recommended by Clarke and Braun (2017) was utilized to analyze the qualitative data for answering the last two research questions.
4. Results
4.1. Quantitative findings
1.
Students' Acceptance and Use of Generative AI Applications
As illustrated in Fig. 2, students reported high acceptance levels in Performance Expectancy (M = 3.66, SD = .58), Effort Expectancy (M = 3.61, SD = .59), Facilitating Condition (M = 3.51, SD = .59), and Use Behavior (M = 3.52, SD = .48), indicating a strong belief that these AI tools enhance learning efficiency, are user-friendly, supported by adequate resources, and are actively utilized in their studies. However, students admitted a relatively lower influence from Social Influence (M = 3.31, SD = .54), suggesting less perceived pressure or motivation from peers and educators to use these technologies. The standard deviations across these constructs imply a moderate to low variability in responses, emphasizing a consensus among students on the utility and adoption of generative AI applications in English learning, except for social factors, which seem to play a less significant role. This pattern reveals that while students are highly motivated by the perceived benefits and ease of use of AI tools, along with the supporting conditions for their usage, they are less persuaded by peer or societal pressures in their decision to adopt such technologies for English learning.
2.
Differences by English Learning Performances
Fig. 2
Download: Download high-res image (266KB)
Download: Download full-size image
Fig. 2. Results of the descriptive statistics.

The analysis of differences in the acceptance and utilization of generative AI applications among low- and high-performing English learners utilized the Mann-Whitney U test, a non-parametric test that assesses whether two independent samples originate from the same distribution. The focus was on five constructs: Performance Expectancy, Effort Expectancy, Facilitating Condition, Social Influence, and Use Behavior. The results presented in Table 2 did not reveal any statistically significant differences between the two groups of students across these constructs, indicating that the level of English learning performance does not significantly influence students' acceptance and utilization of generative AI applications.
Table 2. Results of mann-whitney U test.

Empty Cell	Performance Expectancy	Effort Expectancy	Facilitating Condition	Social Influence	Use Behavior
Mann-Whitney U	59.50	42.50	47.50	64.00	51.00
Z	−.87	−1.82	−1.56	−.63	−1.33
Asymp. Sig. (2-tailed)	.39	.07	.120	.53	.18
Exact Sig. [2∗(1-tailed Sig.)]	.40b	.07b	.13b	.57b	.20b
a. Grouping Variable: group.
b Not corrected for ties.
Specifically, the Mann-Whitney U values and the corresponding Z scores for each construct—Performance Expectancy (U = 59.50, Z = −.87), Effort Expectancy (U = 42.50, Z = −1.82), Facilitating Condition (U = 47.50, Z = −1.56), Social Influence (U = 64.00, Z = −.63), and Use Behavior (U = 51.00, Z = −1.33)—suggest that the distributions of responses between low- and high-performing students were relatively similar. The asymptotic significance (Asymp. Sig.) values, which provide a two-tailed p-value for each test, further support this interpretation. None of the constructs showed a p-value low enough to denote statistical significance (all p > .05), with the closest to significance being Effort Expectancy at p = .07, suggesting a trend but not enough evidence to assert a statistically significant difference.
The exact significance values, corrected for ties in the data, provide a more precise measurement of the p-value but similarly indicate no statistically significant differences (Performance Expectancy p = .40, Effort Expectancy p = .07, Facilitating Condition p = .13, Social Influence p = .57, Use Behavior p = .20). This indicates that both low- and high-performing students perceive and utilize generative AI applications in English learning in comparably positive ways, without significant variance attributed to their performance levels.
3.
Correlation
As presented in Table 3, the Spearman correlation analysis revealed that Performance Expectancy was strongly correlated with Effort Expectancy (ρ = .82, p < .001), Facilitating Conditions (ρ = .55, p < .001), Social Influence (ρ = .73, p < .001), and Use Behavior (ρ = .87, p < .001), indicating a consistent pattern where higher expectations of AI's impact on learning performance were associated with greater ease of use, environmental support, social endorsement, and actual usage. However, the correlation between Performance Expectancy and GPA was not significant (ρ = −.06, p = .76), suggesting that students' optimistic expectations of AI tools did not reflect in their academic grades.
Table 3. Results of the Spearman correlations.

Empty Cell	Empty Cell	Effort Expectancy	Facilitating Condition	Social Influence	Use Behavior	GPA
Performance Expectancy	ρ	.82a	.55a	.73a	.87a	−.06
p	.000	.004	.000	.000	.77
Effort Expectancy	ρ		.56a	.81a	.94a	.22
p		.003	.000	.000	.30
Facilitating Condition	ρ			.37	.66a	.07
p			.07	.000	.73
Social Influence	ρ				.82a	.06
p				.000	.76
Use Behavior	ρ					.11
p					.61
a
Correlation is significant at the .01 level (2-tailed).
Further analyses pointed out that Effort Expectancy, Facilitating Conditions, and Social Influence were positively correlated with Use Behavior, with Effort Expectancy showing the strongest correlation (ρ = .94, p < .001). These results highlight the importance of perceived ease of use, available support, and peer influence in driving the adoption and utilization of AI tools in learning. Nonetheless, none of these factors showed a significant correlation with GPA; for instance, Use Behavior itself was weakly correlated with GPA (ρ = .11, p = .61). This underlines a critical insight: while students might actively engage with AI tools in their English learning journey, motivated by positive perceptions and encouragement from their surroundings, such engagement does not necessarily lead to improved academic outcomes as measured by GPA. The lack of significant correlation between the use of AI in education and GPA points to a complex relationship that requires further exploration to fully understand how technology integration affects academic success.
4.
Prediction
As depicted in Table 4, the Kendall–Theil regression analysis disclosed that Performance Expectancy was strongly regressed on Effort Expectancy (τ = .68, p < .001), Facilitating Condition (τ = .42∗∗, p < .001), Social Influence (τ = .57∗∗, p < .001), and Use Behavior (τ = .74∗∗, p < .001), indicating a robust positive relationship between students' expectations about the efficacy of AI tools and their perceptions regarding ease of use, available support, social endorsement, and actual usage levels. Despite these strong correlations, the regression analysis revealed a non-significant relationship between Performance Expectancy and GPA (τ = −.05, p = .72), suggesting that the high anticipations of AI's impact on learning did not correlate with improved academic performance.
Table 4. Results of Kendall–Theil regression.

Empty Cell	Empty Cell	Effort Expectancy	Facilitating Condition	Social Influence	Use Behavior	GPA
Performance Expectancy	τ	.68∗∗	.42∗∗	.57∗∗	.74∗∗	−.05
p	.000	.01	.000	.000	.72
Effort Expectancy	τ		.422∗∗	.66∗∗	.83∗∗	.13
p		.01	.000	.000	.38
Facilitating Condition	τ			.26	.51∗∗	.04
p			.11	.001	.77
Social Influence	τ				.65∗∗	.09
p				.000	.58
Use Behavior	τ					.07
p					.66
Furthermore, the study extended the regression analysis to explore how Effort Expectancy, Facilitating Condition, and Social Influence are associated with Use Behavior and GPA. Effort Expectancy exhibited a significant positive regression with Facilitating Condition (τ = .42∗∗, p = .01), Social Influence (τ = .66∗∗, p < .001), and Use Behavior (τ = .83∗∗, p < .01), affirming the strong linkage between ease of use and the supportive environment, peer influence, and utilization of AI tools. However, its correlation with GPA was statistically insignificant (τ = .13, p = .38), highlighting a disconnect between ease of use and academic achievements. Similarly, while Facilitating Condition and Social Influence were positively regressed on Use Behavior, indicating their importance in promoting AI tool usage, their correlations with GPA were negligible and statistically non-significant. These findings underline a critical insight: the factors driving the adoption and active use of AI in English learning—while interconnected and significant within the technological acceptance framework—do not directly translate into higher academic outcomes, as evidenced by the lack of significant regression outcomes with GPA.
4.2. Qualitative findings
4.2.1. Student voices
Based on the thematic analysis of the students' responses regarding the effects of generative AI applications on their English learning experiences before and after the emergence of these technologies, the following themes emerge:
Theme 1: Improved Efficiency and Convenience
Following the adoption of AI applications, many students have noted a marked improvement in the efficiency and convenience of their English learning process. These technologies have transformed activities that were traditionally labor-intensive and slow, such as researching relevant information or constructing written assignments, making them significantly faster and less cumbersome. The integration of AI tools has facilitated a streamlined approach to learning, where students can access and manipulate information with unprecedented ease. This has not only expedited task completion but also reduced the mental load and effort required, allowing students to focus more on understanding and less on the mechanics of learning. As a result, students reported that their study sessions became more productive and less time-consuming, effectively enhancing their overall learning experience and making the process more enjoyable and manageable.
After becoming familiar with AI, it became easier to find various information. Modifying data became more manageable, and language learning became more enjoyable than before. (S4)
Before knowing about AI applications, my work consumed much time. After learning about it, tasks became easier. (S8)
Before I knew about AI, working felt time-consuming. Since AI applications, everything has become much easier and faster. (S19)
Theme 2: Enhanced Learning Experience
The introduction of AI applications into English language learning has profoundly enhanced the educational experience, making it more engaging and effective for students. These tools expand access to diverse information, enabling learners to explore various aspects of English with ease and helping them grasp complex topics through tailored explanations. Furthermore, AI technologies provide comprehensive feedback on students’ writing and language usage, covering grammatical accuracy as well as style and tone, all of which are critical for effective communication. Students reported that AI applications made learning more enjoyable and interactive, transforming passive study into dynamic engagement. This immediate and detailed feedback fostered a more productive learning environment, allowing students to correct mistakes and refine their skills on the fly, thereby boosting their confidence and proficiency in the language.
Before discovering AI, learning English was inconvenient and time-consuming for me. Each aspect of learning posed challenges. However, after discovering AI, learning English became much easier and more convenient. AI has made learning or working much more efficient. (S10)
Before using AI applications, my written language was imperfect, and lecturers would often provide suggested words after I submitted assignments. After using AI applications, my writing style improved significantly because we adjusted the words to suit the desired mood or tone. (S11)
Before I got to know about AI applications, learning English for me was difficult because finding vocabulary had to be looked up in books, and it was also difficult to find exercises to develop listening, speaking, reading, and writing skills. After I got to know AI applications, my English learning became easier. (S18)
Theme 3: Increased Confidence and Skill Development
The integration of AI applications in English language learning has significantly elevated students' linguistic confidence and accelerated their skill development in areas such as writing, grammar, and vocabulary. The responsive and interactive nature of AI tools, which provide instant, precise feedback, is largely responsible for this advancement. Students explicitly noted how this immediate correction of errors was transformative, allowing them to promptly recognize and address their linguistic shortcomings. This real-time feedback, as reported by the learners themselves, fostered a deeper engagement with the language and enhanced their understanding of complex grammatical structures and vocabulary. The AI tools catered to the individual learning needs of students, providing them with corrections and suggestions that directly addressed their specific challenges. This personalized approach not only sharpened their language proficiency but also instilled a sense of accomplishment and boosted self-confidence. Over time, the continual use of AI tools allowed students to take greater risks with their language use, engage more deeply with challenging materials, and actively build their skills in a supportive, feedback-rich environment.
In this study, students also expressed a heightened sense of empowerment in their learning journey, highlighting how these AI-driven insights and corrections led to substantial improvements in their English skills. This feedback loop, enriched by AI's capabilities, not only enhanced their language proficiency, but also continuously fostered a productive and confident learning atmosphere.
Previously, writing in English was difficult for me due to poor grammar and uncertainty about vocabulary usage. However, with AI's assistance, writing became easier, and it helped me improve my writing skills significantly by correcting grammar and suggesting vocabulary. (S13)
For me, I usually use AI applications to check my answers and ensure their correctness. (S16)
Before I was introduced to AI applications, I learned English only from teachers at school and textbooks. When I got to know AI applications, I felt like my skills had improved a lot. (S17)
Theme 4: Dependency and Cautionary Notes
While many celebrated AI applications for their ability to improve English language learning, some students voiced significant concerns about the technology's potential for overreliance and its limitations. These students advocated for the use of AI as an assistive tool rather than a replacement for traditional, human-centered learning methods. They emphasized the need for a critical approach to AI-generated content, emphasizing the importance of verifying its accuracy and appropriateness. This caution stemmed from an understanding that while AI could significantly aid the learning process by providing immediate feedback and simplifying complex tasks, it was not infallible and might introduce errors or misinterpretations, especially in nuanced linguistic contexts. By advocating for AI as a supplement to, rather than a substitute for, traditional learning, these students highlighted the balance necessary to leverage technology effectively while maintaining rigorous standards of learning and comprehension.
Using AI to assist in writing has shown differences before and after use. Before using AI, many errors might have occurred in our writing, but after its implementation, our writing becomes complete. However, in my opinion, using AI has many disadvantages. (S9)
Before I discovered AI, finding specific words or using the correct words was challenging. Once acquainted with AI, tasks became easier, such as writing essays or finding words. AI reduced work time and increased convenience, although it may make mistakes, so we must use it correctly with basic knowledge. (S14)
If we use AI to write compositions and submit them to teachers without double-checking, it could potentially lead to confusion in the message as Thai is a complex language. Sometimes, AI may not accurately translate Thai language fully. (S15)
4.2.2. Teacher observations
The teacher observations provide comprehensive perspectives on the integration of generative AI applications in English language teaching. Teacher T1 raises concerns about the difficulty in assessing students' progress due to the opaque nature of AI usage, noting, “I may not be able to compare one's ability before and after using AI.” This highlights a fundamental challenge in evaluating the impact of AI on students' writing skills, as the lack of visibility into individual development impedes accurate assessment. Moreover, T1 observes a potential disparity in students' writing performance across different contexts, suggesting that students who heavily rely on AI for assignments may struggle to perform as well in exam settings. This stresses the need for educators to consider how technological dependence may influence students' academic outcomes in various situations.
In contrast, Teacher T2 emphasizes the importance of ethical AI usage and responsible technology integration. Although lacking direct experience with AI in the classroom, T2 advocates for cautious and judicious AI utilization, stating, “To truly enhance their writing abilities, it is advisable for them to avoid excessive dependence on that particular resource.” This stance reflects concerns about maintaining academic integrity and preserving critical thinking skills in an increasingly digitized learning environment. Furthermore, T2 highlights the role of educators in guiding students towards ethical AI usage, highlighting the pedagogical responsibility in shaping students' attitudes and behaviors towards technology.
Conversely, Teacher T3 acknowledges the practical benefits of AI in streamlining tasks and enhancing efficiency but expresses reservations about potential student misuse. T3 warns against indiscriminate AI usage, citing concerns that students may prioritize convenience over depth of learning, stating, "I do not think these applications will benefit them because the students may just opt for an easy way to finish assignments quickly." This viewpoint accentuates the need for comprehensive guidance and supervision in AI usage to ensure that students derive maximum benefits while avoiding pitfalls such as academic dishonesty and superficial learning practices.
Overall, these teacher observations highlight the complex interplay between the benefits and challenges of AI integration in education. While AI offers potential advantages in terms of efficiency and accessibility, concerns about academic integrity, ethical usage, and pedagogical impact necessitate careful consideration. Educators play a crucial role in navigating these complexities, guiding students towards responsible and meaningful AI usage while fostering critical thinking skills and academic integrity.
5. Discussion
5.1. Student acceptance of GAI and the link to learning outcomes
The quantitative findings shed light on students' acceptance and utilization of Generative AI (GAI) applications in English learning. Students displayed high levels of acceptance across various dimensions, including performance expectancy, effort expectancy, facilitating conditions, and use behavior, reflecting a collective belief in the efficacy and user-friendliness of these AI tools. These results are consistent with those observed among EFL students in Ghana (Salifu et al., 2024), Sri Lanka (Sabraz Nawaz et al., 2024), and Malaysia (Foroughi et al., 2023). However, the present analysis uniquely points out the relatively minor role of social influence, suggesting that peer or societal pressures have limited impact on students' decisions to embrace GAI for English learning. Additionally, this study contributes to our understanding by revealing that the differences in acceptance and utilization of GAI between lower- and higher-performing English learners were not statistically significant. This finding indicates a consistent perception and use of GAI applications across different academic performance levels, a dimension not previously examined in depth by earlier studies. Contrary to prior assumptions, these results challenge the notion that academic achievement influences students' acceptance and utilization of AI tools, underlining the widespread positive attitudes towards GAI in English learning contexts (Abdaljaleel et al., 2024; Yilmaz et al., 2023).
Further analysis revealed strong correlations between performance expectancy and various factors such as effort expectancy, facilitating conditions, social influence, and use behavior, emphasizing the interconnectedness of students' expectations and actual usage patterns. Previous research has suggested that all these factors may shape student attitudes toward GAI, which essentially indicate their use behavior of GAI, as confirmed among EFL learners in Jordan (Masadeh et al., 2024), Bangladesh (Rahman et al., 2022), and Thailand (Teerawongsathorn, 2023). The non-significant correlation between GAI use and GPA, however, shows that these favorable perceptions and active engagement with GAI tools did not translate into improved academic outcomes. Similarly, regression analysis emphasized the importance of perceived ease of use, environmental support, and social endorsement in driving GAI adoption and utilization. Yet, these factors did not directly correlate with academic achievements, highlighting a disconnect between technology adoption and educational success. Hence, even though studies have identified the familiarity and readiness of English lecturers to integrate GAI (Kohnke et al., 2023; Moorhouse, 2024) and have encouraged different ways of engaging students with GAI (Anggoro & Pratiwi, 2023; Liu et al., 2024; Wan & Moorhouse, 2024; Zadorozhnyy & Lai, 2023), the findings of the present study stress that greater engagement with GAI does not necessarily lead to improved academic performance, emphasizing the need for a nuanced understanding of the complex relationship between technology integration and learning outcomes.
5.2. GAI in student English learning in higher education
The qualitative findings offer valuable insights into students' perceptions of the impact of generative AI applications on their English learning experiences. One prominent theme that emerges is the enhanced efficiency and convenience afforded by AI tools, as students report that tasks previously deemed time-consuming and challenging became quicker and easier with AI assistance. This aligns with previous research highlighting the role of AI in streamlining learning processes and making language acquisition more accessible (Farrelly & Baker, 2023). Furthermore, students express an improved learning experience with AI, finding language learning more enjoyable and engaging. AI not only facilitates access to information but also provides valuable feedback on writing and language usage, contributing to skill enhancement and confidence building. These findings accentuate the potential of AI to revolutionize language learning by offering personalized support and fostering a more positive and effective learning environment (Barrett & Pack, 2023; Chiu, 2024; Waluyo & Rofiah, 2021).
However, amidst the positive narratives, students also voice concerns about dependency on AI and caution against overreliance on AI-generated content. They emphasize the importance of using AI as a supplementary tool rather than a substitute for human learning, highlighting the need for critical thinking and verification of AI-generated content. This echoes previous studies that have raised ethical and pedagogical concerns regarding the role of AI in education (Alammari, 2024; Apridayani et al., 2023; Cong-Lem et al., 2024). While AI undoubtedly offers numerous benefits, including efficiency and skill development, students' cautious approach reflects the complexity and nuances involved in integrating AI into educational practices. Thus, it is essential for educators to maintain a balance between leveraging AI's capabilities and promoting independent learning and critical thinking skills among students, ensuring that AI complements rather than replaces traditional pedagogical approaches.
Furthermore, teacher observations offer varied perspectives on the impact of generative AI applications on student English learning. One perspective highlights challenges in accurately assessing student progress due to potential discrepancies between exam performance and homework tasks, raising questions about fostering independent writing skills. Conversely, another viewpoint acknowledges AI's potential to enhance writing skills but warns against overreliance and plagiarism, emphasizing ethical AI usage and academic integrity. However, skepticism exists regarding AI's suitability for students, with concerns about its potential to encourage shortcutting and lack of genuine effort, accentuating the importance of guiding students in responsible AI usage (Barrett & Pack, 2023; Kaplan-Rakowski et al., 2023; Kohnke et al., 2023; Kusuma & Waluyo, 2023; Marzuki et al., 2023). These perspectives align with students' voices, reflecting debates on AI's role in education and the need to balance its benefits with ethical considerations to support genuine learning outcomes effectively.
5.3. Implications and limitations
The findings accentuate the significant potential for Generative AI (GAI) applications to enhance English teaching and learning across Thai higher education. With students demonstrating high acceptance levels and consistently positive attitudes towards GAI, educators and institutions have a unique opportunity to harness these technologies to improve language acquisition among diverse student populations. To optimize the use of GAI in educational settings, it is crucial to integrate these tools into the curriculum in ways that complement traditional teaching methods. Educators should focus on designing targeted educational interventions that include GAI tools, providing adequate training for both students and teachers to ensure effective usage. Support structures should be established to assist students in navigating and maximizing the benefits of GAI, thereby reinforcing positive perceptions and increasing technology engagement. Furthermore, the universal acceptance across different proficiency levels suggests that GAI can be a powerful equalizer in language education, helping to bridge gaps and promote inclusivity by providing personalized learning experiences that cater to the needs of both low- and high-performing students. By implementing these strategies, Thai higher education institutions can fully leverage the benefits of GAI to foster a more inclusive and effective English language learning environment.
Nevertheless, the focus on perceived acceptance and utilization of GAI rather than objective measures of learning outcomes may limit the ability to fully assess the impact of these technologies on English language proficiency and academic achievement in Thai higher education. Moreover, the reliance on self-report measures introduces the possibility of biases and inaccuracies in the data, highlighting the need for future research to incorporate more objective assessments and mixed methods approaches to provide a comprehensive understanding of the relationship between GAI adoption and English learning outcomes in Thai higher education. Future research should investigate the direct impact of Generative AI (GAI) on English language proficiency and academic achievement in Thai higher education from a bigger sample size, while also exploring its long-term effects on learners with varying proficiency levels and whether these technologies reduce or widen educational disparities over time.
6. Conclusion
This study contributes valuable insights into the evolving landscape of English learning in Thai higher education, highlighting both the promising potential and the challenges of integrating GAI technologies. While students exhibit a high level of acceptance and perceived benefits from using GAI tools, the direct impact on academic performance remains inconclusive, suggesting that the value of GAI may lie more in enhancing the quality of the learning experience rather than in measurable academic gains. Furthermore, the qualitative feedback from students and teachers alike highlights the importance of a cautious and balanced approach to incorporating GAI into educational settings. Concerns over dependency, ethical use, and the potential for encouraging superficial learning strategies suggest that educators must provide clear guidelines and support for students to navigate the use of GAI responsibly. Ultimately, these findings call for ongoing dialogue among educators, students, and technology developers to ensure that GAI serves as a beneficial adjunct to English learning, fostering both linguistic proficiency and critical academic skills. Going forward, practitioners and policymakers should also consider these findings when developing frameworks for GAI integration to complement traditional learning methods without exacerbating educational inequalities.

