Perspectives of Generative AI in Chemistry Education Within the TPACK Framework

Abstract
Artificial intelligence (AI) has made remarkable strides in recent years, finding applications in various fields, including chemistry research and industry. Its integration into chemistry education has gained attention more recently, particularly with the advent of generative AI (GAI) tools. However, there is a need to understand how teachers’ knowledge can impact their ability to integrate these tools into their practice. This position paper emphasizes two central points. First, teachers technological pedagogical content knowledge (TPACK) is essential for more accurate and responsible use of GAI. Second, prompt engineering—the practice of delivering instructions to GAI tools—requires knowledge that falls partially under the technological dimension of TPACK but also includes AI-related competencies that do not fit into any aspect of the framework, for example, the awareness of GAI-related issues such as bias, discrimination, and hallucinations. These points are demonstrated using ChatGPT on three examples drawn from chemistry education. This position paper extends the discussion about the types of knowledge teachers need to apply GAI effectively, highlights the need to further develop theoretical frameworks for teachers’ knowledge in the age of GAI, and, to address that, suggests ways to extend existing frameworks such as TPACK with AI-related dimensions.

Introduction
What knowledge should teachers possess to effectively use AI-based generative applications like ChatGPT? And how can they ensure they will receive valuable and accurate insights from them? The rise of AI across various sectors, including education, has increased in recent years. This growth rapidly increased last year with the introduction of generative AI (GAI) tools available for public use. Although these tools provide enormous opportunities, they also raise serious concerns (Alasadi & Baiz, 2023). Over the past year, many articles in the education sector, particularly in science education, have showcased innovative research and provided new perspectives on this matter (e.g., Alasadi & Baiz, 2023; Clark, 2023; Hwang & Chang, 2023; Talanquer, 2023). International organizations, universities, and researchers have also published several reports on this topic (Chan, 2023; Holmes & Miao, 2023). These papers, reports, and policy documents emphasize the critical thinking required when employing these tools (Cooper, 2023), highlight potential pitfalls (Alasadi & Baiz, 2023), advocate for novel assessment methods (Chiu, 2023), point to the role of AI-related professional development (Nazaretsky et al., 2022) and transparent system design (Feldman-Maggor et al., 2024a) in the acceptance of educational AI, and express concerns over their possible misuse (e.g., Rahman & Watanobe, 2023).

The emergence of GAI also poses fundamental questions about the skills today’s teachers should have. The technological pedagogical content knowledge (TPACK) framework (Mishra & Koehler, 2006) has proven to be a valuable means to frame teachers’ knowledge concerning technology integration in the classroom (e.g., Blackwell et al., 2016; Reyes et al., 2017; Wang et al., 2018). However, Graham (2011) highlights potential weaknesses in the framework, including the lack of precise definitions and the need to better understand the interactions among the knowledge bases composing TPACK. The initial items used to evaluate TPACK focused on integrating technology with pedagogical or content knowledge (Koehler et al., 2012; Schmidt et al., 2009) but overlooked the digital literacy required. We note that the boundaries between the technological, pedagogical, and content knowledge components of TPACK are often ambiguous, making it difficult to measure each component distinctly (Ning et al., 2024). A step towards clarifying this ambiguity between the TPACK components was taken by Schmidt et al. (2009), and we adopt their framing of technological knowledge (TK) as primarily concerned with technical aspects and not with digital literacy. This probably explains why many studies have recommended expanding the framework to accommodate various forms of digitalization (e.g., Huwer et al., 2019; Thyssen et al., 2023; Valtonen et al., 2017; Viberg et al., 2024).

In the context of the current position paper, we have also observed this issue in relation to AI. Recently, several studies have proposed extensions and interpretations of TPACK to incorporate the AI aspect and the types of knowledge teachers need in order to use GAI tools effectively (Mishra et al., 2023; Celik, 2023; Lorenz & Romeike, 2023; Ning et al., 2024). Building on these, we expand the discussion of TPACK in the age of GAI in science education. We intend to demonstrate how teachers’ content knowledge and pedagogical content knowledge impact their prompt engineering in two primary ways: first, in how teachers formulate prompts, and second, in their ability to evaluate the quality of the output generated by the machine. We then argue that skills such as prompt engineering fall under the technological dimension of TPACK but also require AI-related competencies that are not technological in nature and do not fit into any of the current dimensions of the framework (Holmes & Miao, 2023). This paper demonstrates our position by providing three examples of chemistry education and discussing implications and future research opportunities.

Throughout this paper, we use the common term "prompt engineering" to refer to the process of providing instructions to the chat for accomplishing a certain task and evaluating its output, typically a dialogical process that includes several stages until a satisfactory product is received. We note that the term “engineering” does bring connotations of purpose and planning, which are not always present in teachers’ interaction with the chat and tend to be intuitive and based on the teacher’s knowledge.

Background
Generative AI and Prompt Engineering
GAI can be defined as a technology that leverages deep learning models to generate content such as texts, images, videos, and voice in response to prompts—the input to the models (Lim et al., 2023). A prompt is an initial message or instruction that initiates a dialogue or requests specific information, providing context and guidance for the desired topic or task. AI generative tools such as ChatGPT offer the possibility of human–machine interaction: humans can initiate a prompt and then, after receiving a response, guide the GAI tool with the following prompt. When applied systematically and purposefully to achieve better responses from AI, this new type of human-AI collaboration is termed prompt engineering (Zhao et al., 2021).

Prompt engineering involves defining task descriptions to guide a specific model and is used to retrieve desired outcomes from language models, where the definition of desirable outcomes depends on the end task and the end user (Liu & Chilton, 2022; Short & Short, 2023). The topic of prompt engineering research in machine learning has recently grown (Liu & Chilton, 2022; Strobelt et al., 2022), and with the release of GAI tools such as ChatGPT, end-user prompt engineering has gained more momentum (Short & Short, 2023). One of the important principles of prompt engineering is to find certain classes of words or sentence phrases that yield better outcomes. This principle is essential for technical advancements in machine learning to develop models that can be translated into functional interaction paradigms (Liu & Chilton, 2022). Zamfirescu-Pereira et al. (2023) stressed that crafting effective prompts can be challenging. Their study explored whether non-AI-experts can successfully engage in “end-user prompt engineering.” They demonstrated that prompts can address bias in the model toward generating the desired outputs. Bias in the context of AI can be defined as a systematic tendency of the AI system to make decisions or predictions influenced by factors correlated with the task at hand but not necessarily causally related. This raises issues of fairness that might contradict the pedagogy of inclusion and equity that science education strives to promote (Avraamidou, 2024; Kassam, 2022). Another type of bias that the prompt might influence is hallucinations. Hallucinations result from the fact that large language models (LLMs) use probabilistic modeling for generating the output, which can cause them to “invent” (or “hallucinate”) responses that are not real. The combination of compelling language and the confidence it demonstrates may lead people to accept the LLM as a knowledgeable source even when it provides false information (Azaria & Mitchell, 2023).

In this position paper, we wish to stress the importance of studying the interaction between prompt engineering and teachers’ knowledge.

Teachers’ Knowledge
Shulman’s PCK framework focuses on using teachers’ knowledge during teaching (Shulman, 1987; Tal et al., 2021). Three main components of teachers’ knowledge are discussed in this framework: content knowledge (CK), pedagogical knowledge (PK), and pedagogical content knowledge (PCK). CK refers to the subject matter that is to be taught; pedagogical knowledge (PK) refers to the practices, processes, strategies, procedures, and methods of teaching, as well as the pedagogical content knowledge (PCK) knowledge about learners, curriculum, instructional strategies, and assessment to transform content knowledge into effective teaching of specific content (Bryan et al., 2015; Shulman, 1987). PCK encompasses a teacher’s subject-specific pedagogical knowledge, including the subject matter and the curriculum (Verloop et al., 2001), knowledge of the curriculum, knowledge of testing, knowledge about learners, and knowledge about strategies of passing on knowledge (Magnusson et al., 1999). Shulman indicated that PCK occurs when a teacher interprets the subject matter and finds ways to make it accessible to the students (Shulman, 1987). In other words, PCK includes knowledge about learners, curriculum, instructional strategies, and assessment to transform content knowledge into practical teaching (Shulman, 1987).

Over the past decade, numerous studies have been conducted to examine the impact of teachers’ PCK on their instructional practices across various disciplines (Avargil et al., 2012; Hubbard, 2018; Jin et al., 2015; Rodriguez & Towns, 2019) and on ways to develop teachers’ PCK (Abell, 2008; Marchak et al., 2021; Gess-Newsome et al., 2019; van Driel et al., 2014). These studies encompass teachers’ professional development, pre-service teacher training, and experimental and observational research conducted in classroom settings. Across these studies, there was a unanimous consensus regarding the vital role of PCK in effective teaching. In science education, particularly in chemistry, teachers’ PCK includes their understanding of drawing models, utilizing computer simulations, and constructing three-dimensional models (Avargil et al., 2012; Bryan et al., 2015; Chai et al., 2013).

Another aspect of PCK, emphasized by Tal et al. (2021), is the importance of questioning as a crucial tool for teachers during the instructional process in order to engage students and foster active learning. Their research demonstrated that teachers who pose questions in professional development training can integrate domain-specific subject knowledge, indicating teachers’ PCK. Moreover, Tal et al. (2021) showed that the ability to ask questions is an essential aspect of teachers’ professional knowledge. Consequently, posing questions within context-based research integrates CK with PK and reflects the teachers’ PCK level. Research has indicated how teachers’ PCK is manifested in the assignments they develop for their chemistry classes, thus contributing to their professional growth. This includes assessment knowledge (AK), the ability of teachers to design and implement appropriate tasks to accurately assess students’ knowledge and skills (Avargil et al., 2012; Tal et al., 2021).

As AI grows, discussions emerge about the shift in teachers’ roles. They are transitioning from being the primary source of knowledge to serving as mentors, coaches, and learning facilitators. Given this context, it is essential to re-examine the roles and expertise of teachers (Gess-Newsome, 2015). Although traditional frameworks of teachers’ PCK, as detailed in the canonical science education literature (e.g., the consensus model (Gess-Newsome, 2015)), might be perceived as less relevant in this new era, we will illustrate their continued relevance.

Technological Pedagogical Content Knowledge
The increasing use of technology in education and the need to improve the integration of technological means in teachers’ practice have led to the extension of the PCK framework outlined by Mishra and Koehler (2006). The TPACK framework originated from the assumption that today’s teachers need to know how to use, control, and understand relevant technologies and effectively apply them to improve their teaching (Rap & Blonder, 2016). TPACK contributes to PCK by adding four components: technology knowledge (TK), technological content knowledge (TCK), technological pedagogical knowledge (TPK), and technological pedagogical content knowledge (TPACK). TK refers to knowledge about standard technologies and the skills required to operate them. In contrast, TCK refers to knowledge regarding the relationship between technology and content (Mishra & Koehler, 2006), for example, in the context of chemistry, how to use technology to draw molecules (Cetin-Dindar et al., 2018) and teach with animations (Dorfman et al., 2019) or with YouTube videos (Blonder et al., 2013). TPK refers to knowledge of various technologies’ components and capabilities in teaching and learning settings. Aroch et al. (2024) identified seven modes of technology integration (MOTIs) in chemistry teaching and described the related TPACK for each of these MOTIs. Finally, TPACK is an emergent form of knowledge that integrates content, pedagogy, and technology (Mishra & Koehler, 2006). TPACK is achieved when a teacher knows how technological tools transform pedagogical strategies and content representations to teach particular topics and how technological tools in education and representations affect a student’s understanding of these topics (Marchak et al., 2021).

A recent perspective paper by Mishra et al. (2023) argued that the contextual knowledge (termed XK) dimension that was added to the framework (Mishra, 2019) is sufficient to cover the aspects that GAI necessitates regarding teachers’ knowledge and practices. However, XK is not specific to AI. It is rather broad and generic, encompassing teachers’ familiarity with the available technologies and their understanding of the situational factors impacting their application. We, therefore, find it too general to effectively address some of the important specificities of teachers: GAI interactions. A more AI-specific extension was suggested by Celik (2023), who suggested adding the AI dimension to TPACK, claiming that TK alone is insufficient for capturing what teachers need to know when working with AI tools, particularly emphasizing the ethical dimensions. Similarly, Lorenz and Romeike (2023) suggested extending the TPACK framework with an AI dimension, stressing the need to examine the intersection of pedagogical and technological areas.

These discussions on conceptual frameworks for teacher knowledge with respect to AI exist to contribute concurrently to (or perhaps lag behind) the frantic pace at which AI technologies are being introduced into education, with applications such as developing lesson plans, conducting laboratory experiments, and enhancing problem-solving capabilities (e.g., Araújo & Saúde, 2024; Clark, 2023; Exintaris et al., 2023). Moreover, concerns regarding academic integrity (Eke, 2023) raise questions about assessments and the development as well as implementation of AI-based technology for detection (Alexandron et al., 2024; Moorhouse et al., 2023). Additionally, there is a growing focus on AI literacy among both teachers and students, referring to the skills and competencies necessary to effectively utilize AI technologies (Holmes, 2024; McQuillan et al., 2024). These advances make the discussions on teachers’ knowledge with respect to AI paramount and very timely.

The Aim and Focus of the Position Paper
This position paper discusses the developing landscape of knowledge and skills that science teachers need in the age of AI. As described in the previous section (Introduction and Background), with the rapid development of AI tools, a few researchers have suggested expanding TPACK for AI use (Celik, 2023; Lorenz & Romeike, 2023; Ning et al., 2024; Thyssen et al., 2023). We support their approach and provide a perspective that links TPACK and AI literacy in the context of science education.

We demonstrate ways in which pedagogical and subject matter-specific knowledge remain relevant when applying GAI to create lesson plans and learning activities. Moreover, we discuss whether teachers require additional literacy bases to integrate GAI tools into their teaching practices effectively. These are demonstrated using three examples from a dialogue between a chemistry teacher and ChatGPT, showing that teachers’ PCK is critical to using GAI tools effectively.

We show that prompt engineering falls partially under the “Technological” dimension of TPACK and requires AI literacy.

Thus, this paper contributes to the timely discourse on conceptualizing teachers’ knowledge in the age of AI in two ways. First, it emphasizes the key role of teachers’ TPACK in applying GAI effectively. Second, the paper highlights critical aspects of AI knowledge that fall outside the current TPACK framework and its recent extensions.

Examples from the Dialogue with ChatGPT
Three examples from the dialogue with ChatGPT are constructed in this section. Example 1 demonstrates how teachers’ TPACK is reflected in their use of GAI. Examples 2 and 3 demonstrate aspects outside the TPACK dimensions, justifying the need for an extended framework. In Examples 2 and 3, we identify bias, discrimination, and hallucinations. The choice of these aspects is based on previous literature that highlights these issues as critical aspects of GAI (Alkaissi & McFarlane, 2023; Holmes & Miao, 2023; Tao et al., 2023; Gallegos et al., 2024).

Example 1: Differences Between Molecular and Ionic Materials
The first example is content-related and includes an evaluation of the TPACK component (Archambault, 2016). Using ChatGPT 3.5, a dialogue cycle begins with a prompt, followed by a response. Next, a new prompt is created based on that response, and so forth. During these exchanges, we focus on the teacher’s PCK, specifically their ability to evaluate responses from ChatGPT. At the beginning of a dialogue, the teacher should know how to create the prompt and use Chat technology. We identified a prompt sequence that falls partially under the T component of TPACK for GAI. Following the prompt, the teacher should evaluate the Chat output and use a follow-up prompt when necessary. To do so, the teacher needs to apply PCK. The teacher requires PCK to effectively create prompts that use content-specific jargon, ensuring that the prompts have a clear educational purpose. Additionally, this knowledge is essential for teachers to accurately assess the content of the responses they receive and, based on that evaluation, create the follow-up prompt. The chemistry educator’s dialog with the chat focused on the distinctions between identifying ionic and molecular materials and exploring strategies for teaching these differences. The first example, which comprises eight prompts and eight ChatGPT responses, resulting in the full dialogue, can be found here in the following log: https://chatgpt.com/share/e028efce-be72-4a48-a089-69560d4bf938. We present parts of the dialogue below.

The dialogue began with the following prompt created by the chemistry educator: “I just finished teaching about molecular and ionic materials, and now I want to teach my students about the differences between these two types of materials” (Prompt 1). In prompt five, the teacher asked about common misconceptions in chemistry:

What about students’ confusion about materials such as NaOH and CH3CH2OH? Can you add a question that stresses this topic? Can you suggest an activity? (Prompt 5).

The teacher refers to a misconception regarding the difference in “OH” as a polyatomic ion—OH- or “OH” as a part of the functional alcoholic group R-OH in an organic molecule. This common misconception may emerge after students learn the acid–base topic (Ouertatani et al., 2007). The teacher was aware of the misconception and aimed to address it while teaching about molecular and ionic compounds. In the response, the chat provided an activity to help distinguish between molecular and ionic materials in general. The ChatGPT did not address the teacher’s concern regarding the abovementioned misconception. Then, the teacher continued and asked in prompt 6 for a more specific reason for the confusion, which reflected her PCK. Although the chat provided a more satisfactory answer, the context of the ethanol molecules was still inaccurate; the chat “explains” as part of the answer to prompt 6 “CH3CH2OH is a molecular compound where the carbon and hydrogen atoms are held together by covalent bonds, and the oxygen atom is bound to hydrogen atoms within the molecule.”

The teacher needed to apply her CK to identify the chat’s inaccuracy in prompt 7: “I think that something is not accurate in your response in this part: ‘CH3CH2OH is a molecular compound where the carbon and hydrogen atoms are held together by covalent bonds, and the oxygen atom is bound to hydrogen atoms within the molecule.’ It should be ‘CH3CH2OH is a molecular compound where the carbon and hydrogen atoms are held together by covalent bonds (one of the carbons held together with 3 hydrogens and one of the carbons held together with 2 hydrogens), between the two carbons there are also covalent bonds. The carbon which held together with two hydrogens also held together with an oxygen atom. The oxygen atom is bound to a hydrogen atom within the molecule.’” In response, the chat corrected its mistake and generated a more accurate response.

In this teacher-ChatGPT dialog, CK and PCK were reflected through the teacher’s prompt. The CK is concerned with the molecular and ionic substances in terms of the particles that comprise them and the bonds that hold them together. The chemistry teacher’s PCK was applied as well. She was familiar with students’ misconceptions caused by misunderstanding concepts at the symbolic level (Johnstone, 1991), and she aimed to address this misconception in order to support the learning of all the students in her class (Baumann & Melle, 2019; Easa & Blonder., 2022, 2024). In addition, ChatGPT did not provide an answer with accurate chemical writing, and the teacher had to realize that she should change it before presenting it to her students.

Example 2: Gender Bias
The second example demonstrates gender bias in the generation of a picture. Using ChatGPT 4, which enables the generation of pictures, we show how this bias could be addressed using additional prompts. In this example, the chemistry teacher’s dialog with the chat focused on chemistry-related professions and aimed to generate pictures of those professionals for a PowerPoint presentation. The teacher used the following prompts: prompt 1, create an image of a chemist; prompt 2, create an image of two chemists; prompt 3, create an image of two chemists, one man and one female; prompt 4, create an image of two chemists, one female and one male. Only in prompt 4 the teacher received a representative male and female photo. This example is shown in Fig. 1. Currently, ChatGPT 4 does not enable the generation of a link when generating pictures, but we can easily download the pictures presented in Fig. 1. In the final result, the chat was “convinced” that a female should be added to the image (Fig. 1D).

Fig. 1
figure 1
Figure generated from ChatGPT4. A The output of the prompt: create an image of a chemist. B The output of the prompt: create an image of two chemists. C The output of the prompt: create an image of two chemists, one male and one female. D The output of the prompt: create an image of two chemists, one female, and one male

Full size image
Another bias, or more accurately, a stereotype that we noticed in Fig. 1, is the background of a traditional “wet lab.” However, not all chemists use chemicals nowadays—some chemists are computational chemists. We assume that the data on which ChatGPT trained defines a chemist in a wet lab as the default and not in an office environment. To mention another setting of chemists doing their job, as shown in Fig. 2, the default image we received was a white male in a wet lab. Then, when we asked for a computational chemist, we received an image of a male in a technological environment, and a female appeared in the image only when we asked for two computational chemists. Another issue in Figs. 1 and 2 was the race white. In Fig. 2, we used a prompt to deal with the representational bias described in Fig. 2’s description.

Fig. 2
figure 2
Figure generated from ChatGPT4. A The output of the prompt: create an image of a chemist. B The output of the prompt: create an image of a computational chemist. C The output of the prompt: create an image of two computational chemists. D It appears that both characters are depicted as white. Could this be changed to avoid creating racial bias? E Can you add a female chemist to the image?

Full size image
Example 3: Hallucination
The third example demonstrates hallucinations using ChatGPT 3.5. In this example, the teacher was looking for references about students’ misconceptions in chemistry. This dialog was comprised of six prompts and six ChatGPT responses. The chemistry teacher was aware of potential hallucination and critically checked the references provided by ChatGPT. The chat did not provide reliable references, but in some cases, the authors and the journals were real. Therefore, in the second prompt, the teacher wrote: “The list you provided me was not accurate: Reference 1—Real authors, but I did not find the paper, Reference 2- It’s a real book name but with different editors. Reference 3 to Reference 6—I did not find the papers in Google Scholar or the specific journals. Can you check it and provide me with a reliable list of references with links to abstract or full text? If possible, add doi/ ISBN.” In the response, the chat admitted only some of the mistakes, for example, “This paper may not exist. Still, Bassam Z. Shakhashiri has written extensively on chemistry education. You might find relevant material in his works.” The full dialogue can be found here: https://chat.openai.com/share/da87a7a5-2fd2-4406-a4c7-e1caa8ce1107.

Note: GAI tools appear at a rapid pace, and their response to certain prompts is not stable. While this paper does not aim to compare different versions of ChatGPT or any other GAI tool, we did evaluate the robustness of the above examples by testing them on both ChatGPT 3.5 and ChatGPT 4, running each example multiple times using identical prompts to ensure that our conclusions are not based on a non-representative response taken from a single dialogue.

Discussion
The discussion is organized into three sections aligned with the examples provided above. First, we discuss teachers’ TPACK when using GAI. Second, we address aspects outside the TPACK dimensions, justifying the need for an extension or modification of the framework, as suggested in previous studies (e.g., Thyssen et al., 2023; Celik, 2023; Lorenz & Romeike, 2023; Ning et al., 2024). The examples used were specific to chemistry education; however, there is no reason that the same logic sequences cannot be used in other subjects. Finally, we summarize the approach suggested in this paper and outline future directions.

Teachers’ TPACK When Using GAI
Example 1 demonstrated that teachers’ knowledge of GAI tools is highly dependent on their TPACK. First, teachers should know how to effectively formulate prompts, and this prompt engineering partially falls under the T component of TPACK. Teachers should also be able to evaluate the chat output and use a follow-up prompt when necessary. This requires teachers to apply their PCK. Example 1 also showed how PCK components emerged in chemistry teachers’ interactions with ChatGPT. A central aspect of this was the teacher’s ability to validate and critically assess content generated in ChatGPT responses through the lens of their CK and PCK. This insight is aligned with previous research arguing that AI tools will not replace teachers but can serve as assistants if teachers have the needed PCK (Backfisch et al., 2020). Although ChatGPT can generate information, curriculum suggestions, questions, quizzes, suggestions for experiments, and even full lesson plans, we showed that teachers must still apply their disciplinary and pedagogical knowledge to evaluate the chat recommendations. This evaluation requirement has also been highlighted in other studies. For example, a recent study on ChatGPT-based hints to help solve mathematical questions found that ~ 30% of the hints produced by the bot were erroneous and should not be used (Pardos & Bhandari, 2023). Another study (Dunder et al., 2024) found that ChatGPT 3.5 could help solve simple programming questions but may not be accurate when the questions are complex. Küchemann et al. (2023) suggested that a strong understanding of the subject is crucial to overcome ChatGPT’s limitations in generating consistent tasks. This aligns with our example 1, which demonstrated the importance of PCK and TPACK for applying GAI in educational contexts.

When using the Internet, users know that anyone can upload almost any content, whether accurate or not. This fact necessitates critical thinking and evaluation of online materials. However, users can usually validate these materials using generic criteria such as checking the identity of the website’s owners and the update time (Belova & Krause, 2023; Feldman-Maggor et al., 2016). In example 1, we found an error in the chat’s ability to differentiate between intermolecular and covalent bonds. Teachers should be aware of such possibilities and employ their PCK to identify them. However, critical thinking is not the only aspect of PCK. For instance, the error described in example 1 can occur due to algorithm bias or a mistake in the underlying data upon which the chat’s algorithm relied. This understanding that outcomes from GAI are influenced by the data it relies upon is a skill that is part of AI literacy (Pargman et al., 2023). In what follows, we discuss this point further using examples 2 and 3.

Aspects that Fall Outside the TPACK Dimensions
In example 2, the teacher identified a common gender and race bias in pictures generated using ChatGPT-4, which is known as representational bias in AI literature (Baker & Hawn, 2022; Kizilcec & Lee, 2022); moreover, GAI models are generally skewed towards content that reflects western perspectives and people (Cooper, 2023). Being aware of this bias, the teacher asked to revise the images via a sequence of prompts, eventually generating images without bias. In this example, the teachers’ TPACK was not enough to critically evaluate the chat output. Rather, s/he had to be aware of potential biases that are not part of their PCK or the ability to use technology within the chemistry discipline. She used her PCK when she identified the stereotype of a wet lab as a default image generated by ChatGPT and then asked for an image of a computational chemist to present chemists’ work in another setting. We demonstrated that the result could be improved if a teacher is aware of bias. This example aligns with the findings of studies showing that, in some cases, user prompts can either create or eliminate bias (Tao et al., 2023; Zamfirescu-Pereira et al., 2023). Although example 2 demonstrates three types of bias, other biases or discrimination can occur when using AI (Feldman-Maggor et al., 2024b). Given that situational cues (such as gender bias exhibited in learning materials) can trigger social identity threat, which in turn can lead to a decrease in scientific participation (e.g., Murphy et al., 2007), teachers’ ability to identify and treat potential GAI’s biases should be an important part of their AI competencies.

Another source of bias or equity issues arises because most AI tools operate mainly in English, which has a significant advantage due to the availability of large-scale training datasets (Ariely et al., 2023; Gallegos et al., 2024; Xu et al., 2024). Therefore, teachers from English-speaking countries will gain more from GAI tools than teachers who are not. This gap will also affect students of non-English-teachers, who are impacted by their teachers’ knowledge.

Example 3 showed how prompt engineering can help in receiving more accurate references. However, it demonstrated that the teacher needed to use digital literacy to check if the reference list provided by ChatGPT was reliable. Unreliable references generated by AI are often referred to as “hallucinations” (Athaluri et al., 2023). This aligns with Ji et al. (2023) who explained that “hallucinations” refer to a phenomenon where the model generates outputs that seem reasonable or convincing but are incorrect or not real (Ji et al., 2023). Although example 3 demonstrates hallucinations requiring AI literacy, hallucinations might also necessitate PCK to ensure that the teacher can evaluate the generated information. The need to apply critical thinking is common to both kinds of output evaluation. This requirement is also mentioned in other papers on the use of GAI in education (e.g., Cooper, 2023; van den Berg & du Plessis, 2023). Not surprisingly, there is already evidence of the risk of hallucinations in other disciplines. For example, in the field of medical science, it was demonstrated how ChatGPT reported, with apparent confidence, a medical phenomenon that, in reality, has not yet been reported (Alkaissi & McFarlane, 2023). Also, recently, two lawyers were fined in court for submitting ChatGPT’s hallucinations as facts without verifying them (Shin, 2023). These cases demonstrate the importance of critically evaluating the chat’s output to use it appropriately.

The TPACK framework enabled us to evaluate the teacher-chat dialogue as a new technology and illustrated the flexibility and utility of generative modeling ChatGPT. From a technological perspective, ChatGPT enables a dialogue and answers questions. Unlike standard “search engines” (e.g., Google search), which retrieve information according to a combination of words or specific questions, GAI tools enable users to ask follow-up questions, comment, and reflect on the retrieved information. This process could improve the technology and make it more accurate and appropriate for educational and pedagogical needs. This link between the TPACK-Prompt-Chat response is vital since it emphasizes the importance of the teacher’s previous knowledge. However, the TPACK framework was originally developed along with the advancement of communication technologies and the introduction of Web 2.0. This raises the question of whether the distinction between AI and other existing technologies requires a distinct framework for teachers’ knowledge. We join recent studies (Celik, 2023; Mishra et al., 2023) and stress that the existing TPACK framework is insufficient for integrating GAI tools into teaching.

Summary and Future Directions
The current paper highlights that prompt engineering adeptness should be integrated into teachers’ TPACK. Specifically, we claim that TPACK regarding GAI involves the ability to conduct ongoing dialogue with ChatGPT. Following the aspects of awareness for critical thinking, bias, and hallucinations, we suggest that AI literacy should be considered in addition to the T of TPACK. Mishra et al. (2023) and Celik (2023) suggested that although TPACK remains relevant, it is no longer sufficient in its current form. Mishra et al. (2023) advocate for the continued relevance of TPACK in the era of GAI but recommend enveloping TPACK within what they term XK. XK goes beyond the immediate context to consider how GAI will alter individuals, society, and the broader educational context. This includes being familiar with various technologies and understanding the educational institution’s environment, which includes policies at the school, district, state, or national level that can impact their teaching practices. We argue that these new frameworks are still not specified enough for AI literacy and demonstrated their limited ability to include three essential aspects. These days, with the growing use of GAI, we call on the international education research community to study the interaction between teachers’ knowledge and GAI tools used to conceptualize a proper extension of TPACK (and/or other teacher competency frameworks).

A better conceptualization of the TPACK extension is vital not only for research purposes. Applying the extended framework will also support teachers’ education and professional development programs. For example, prompt engineering should be considered while designing teachers’ professional development activities on integrating AI tools into teaching. As PCK changes during the teachers’ career (Blonder & Vescio, 2022; Tal et al., 2021), its impact on teachers prompts engineering practices, which should be considered when designing GAI-related training for in/pre-service teachers. Professional development activities should stress the “invisible” aspects of AI, which require critical thinking that can cause identity bias, discrimination, and even hallucinations. To summarize, with the development of GAI tools, questions regarding the teachers’ role, teachers’ knowledge, and the AI literacy teachers need to develop in order to excel in this role should be further studied and discussed.

Finally, the TPACK framework is broad, enabling many researchers and educators from different fields to use it over the years (e.g., Blackwell et al., 2016; Reyes et al., 2017; Wang et al., 2018). However, this broad scope and the lack of specificity also serve as limitations, possibly explaining why many extensions have been suggested for different technologies over time (e.g., Huwer et al., 2019; Thyssen et al., 2023; Valtonen et al., 2017; Viberg et al., 2024). This position paper focused on TPACK, and similar to Lorenz and Romeike (2023), we stress the need to better understand the T dimension, particularly regarding AI. We addressed this by viewing prompt engineering as part of the T dimension and by connecting critical aspects, such as knowledge about bias, to AI literacy beyond TPACK. Although our position paper focused on GAI, we suggest that future studies should also focus on TPACK to modify the framework for future technologies and in other fields.

