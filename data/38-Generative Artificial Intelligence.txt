Generative Artificial Intelligence in distance education: Transformations, challenges, and impact on academic integrity and student voice

Abstract
Generative artificial intelligence (GenAI) has reshaped distance education by prompting a shift towards student-centred initiatives to promote responsible AI usage. This study explores the transformative impact of GenAI in distance learning and focuses on academic integrity and student voices. This study uses the technology acceptance model to investigate how GenAI influences distance education. Three objectives guide the study: (1) exploring the transformative effects of GenAI in distance education, (2) understanding its impact on academic integrity, and (3) examining its influence on students’ academic voices in a South African open distance and e-learning university. Qualitative data was gathered through interviews with lecturers, open-ended evaluation questions with administrative staff, and focus group discussions with first-year students in an academic writing module. Findings highlight the need to bridge the gap between negative perceptions of AI’s impact on academic integrity and positive views on its potential to boost student confidence in learning. This research study aims to analyse GenAI’s role in distance education and provide insight into its potential, challenges, and strategies to ensure academic integrity and preserve students’ voices.

Keywords  Academic integrity;  artificial intelligence (AI); ChatGPT; distance education;  generative artificial intelligence (GenAI); student voices.

Introduction  Generative artificial intelligence (GenAI) stands as a pivotal force in higher education institutions (HEIs) (Chugh et al., 2023; Maphoto et al., 2024; Ogata et al., 2024; Qasim et al., 2022) and serves as a foundation for innovation that not only reshapes traditional paradigms but also brings in an era of unprecedented possibilities for teaching and learning (Baidoo-Anu & Ansah, 2023; Fullan et al., 2023; Rudolph et al., 2024). Amidst this paradigm shift, one facet stands out – the introduction of GenAI, such as ChatGPT. Far from being a mere technological augmentation, the integration of ChatGPT into distance education prompts a re-evaluation of pedagogical norms, raising critical questions about its transformative influence on assessment methodologies (Naidu & Sevnarayan, 2023), academic integrity (Sevnarayan & Maphoto, 2024), and the dynamics between student voices (Ali et al., 2023) and authorship. As education embraces the capabilities of GenAI, it is essential to acknowledge the positive disruptions it introduces. Amid the potential for a paradigm shift in virtual interactions through adaptive responses (Rasul et al., 2023), there lies a need for careful exploration to consider the challenges identified by Cotton et al. (2023) and Naidu and Sevnarayan (2023). In the context of AI tools such as Copy.AI, QuillBot, Grammarly, Jasper AI, Notion AI, Jenni.AI, Wordtune, ProWritingAid, AI Writer, Rytr, and Writesonic, which collectively display diverse capabilities (Ladha et al., 2023), we explore specifically ChatGPT’s capacity to transform online assessment methodologies. This exploration aims to empower lecturers to tailor learning experiences to individual needs.  Scholars have argued that the “proliferation of GenAI technologies like ChatGPT poses significant challenges to traditional assessment methods, particularly essays and online examinations” (Rudolph et al., 2024, p. 11). Consequently, Popenici (2023) offers a critical view of AI and states that “[a]ny technological solution and adoption involve a certain ideological choice and influence, consciously or not” (p. 381). This statement emphasises the need to analyse the ideological implications of AI integration in education critically, and it suggests that it may not always align with the values and aims of educational institutions. Popenici (2023) further emphasises, “The blind trust in and adoption of new tech by educators... becomes even more dangerous in the era of AI. The challenge ahead for education is to become users of AI for the benefit of our students and institutions rather than simple subjects of AI” (p. 381). This stance highlights the importance of approaching AI integration in education with vigilance and critical inquiry rather than unbridled enthusiasm. Popenici et al. (2023) note that “the advantage of ChatGPT is that it came as a mirror for education. It shows where we are because we are completely unprepared for reality. We lose perspective on what matters when we have this engine of mediocre text” (p. 323). This statement reveals educational institutions’ unpreparedness for AI technology’s realities. When our students generate text that may be perceived as mediocre or lacking in depth, ChatGPT exposes the limitations of current educational approaches in encouraging critical thinking, creativity, academic integrity and authentic student voices. They go on further to add that:  The very amusing thing, and it is laughable, is that technology is showing us how far we are from what we should do. The risk is that we are going to lose our legitimacy entirely. It’s a massive challenge because we turned assessment into this industrial process of mass assessment, with no quality, no look of originality, and need of substance. This is what you have to submit; use citations; use good grammar, and good syntax, and you don’t do massive mistakes. It’s good to go. You graduate. You’re good. It’s fantastic when we turn the whole system to this; it’s just that we lost the plot, and then it is a disgrace. Technology is showing us how much we are at risk. It is striking at the core of education. This is a consequential moment (Popenici et al., 2023, p. 323).  Similarly, Lindgren (2023) warns against the naturalisation of dominant views and priorities within AI discourse and argues the importance of critical analysis in questioning the social and political implications of innovation, progress, control, and efficiency. Concurrently, we confront concerns about the authenticity of students’ work, academic integrity, and the impact on students’ intellectual autonomy. Popenici et al. (2023) argue, “If you reduce learning to assessment and the assessment can be outsourced by students to just write a sentence and think a bit about the text, you have no motivation. Why would I do that? Why would I learn anything? Because I can just give it this AI solution. The kind of implications for universities are massive” (p. 324). The integration of GenAI in HEIs represents not just a technological leap but a fundamental shift in the distance educational context.  According to Yu (2024), the integration of ChatGPT into distance contexts transcends mere technological augmentation; it marks a profound reconfiguration of the higher education trajectory. The foundation of remote learning and online assessment undergoes a metamorphosis, challenging conventional wisdom about evaluation. The reliability of AI-generated responses to reflect a student’s comprehension and originality becomes a central question and demands a reconsideration of assessment methodologies in this new paradigm. For Perkins (2023), academic integrity, a foundation of educational excellence, faces a formidable test in the era of ChatGPT. The potential for blurred lines between collaboration and unauthorised assistance looms large and raises concerns about plagiarism and academic dishonesty. Does the integration of GenAI empower students to articulate their thoughts more effectively, or does it dilute the essence of authorship, posing a threat to the authenticity of their academic contributions? In this article, we explore the challenges and opportunities presented by AI and provide insights into how lecturers and HEIs can engage with these changes effectively. We pose the following research questions in this article:  How has ChatGPT influenced and transformed distance education?  How does ChatGPT impact on academic integrity in distance education?
• In what ways does ChatGPT affect students’ academic voice in the context of distance learning?  Literature review  We acknowledge the scope and contribution of literature in advancing the debate around the challenges and opportunities GenAI presents within the higher education context. However, preference is given to the most pertinent and contemporary peer-reviewed scholarship on GenAI’s and ChatGPT’s specific impact on tertiary teaching and learning.  Distance education in the age of AI and ChatGPT  Since its November 2022 launch (OpenAI, 2022), OpenAI’s ChatGPT-3 has gained attention, amassing over 100 million users by January 2023. Within HEIs, concerns about GenAI, driven by profit motives, have been voiced (Ormond, 2023). However, Mollick and Mollick (2022) counter this view by proposing that GenAI can enhance learning by overcoming barriers like improving transfer, debunking explanatory depth illusions, and training critical evaluation skills. Our study focuses on the latter aspect as students’ abilities to critically evaluate information shapes academic voice and integrity. Distance education, amid emerging GenAI, presents unique opportunities and challenges. While GenAI can personalise learning, challenges include bias, overreliance on AI hindering critical thinking, and access disparities (Bozkurt & Sharma, 2023). Bozkurt and Sharma (2023) advocate for personalised, adaptive, student-centred approaches that are feasible in the Global North but challenging in the less technologically developed Global South. In addition, open distance e-learning (ODeL) institutions face ‘transactional distance’ (Moore, 2013), separating lecturers from students. With students managing their learning, support is mediated through technology like learner management systems and communication platforms (Bozkurt & Sharma, 2023). In the student-centred ODeL approach, ChatGPT would form part of such mediatory technology.  Research by Holmes and Porayska-Pomsta (2023) and Maphoto et al. (2024) reveal a gap in understanding the impact of GenAI on academic integrity in the Global South. This relates specifically to the potential of South African ODeL HEIs to facilitate a dialogue that extends beyond student-facilitator interactions to include conversations initiated with GenAI systems (Bozkurt & Sharma, 2023). However, caution is advised, as GenAI should complement, not replace, personalised support from lecturers (Bozkurt & Sharma, 2023). ChatGPT, as a secondary digital facilitator, automates traditional tasks, reducing transactional distance but necessitating continued lecturer guidance. Bozkurt and Sharma emphasise the integration of GenAI with core educational values such as equity, diversity, and inclusivity and consider the dynamic nature of ODeL contexts (2023, p. vi). In this context, the widespread use of distance education and the rise of GenAI highlight the need for thoughtful integration that aligns with educational values in the digital age.  Distance education, academic integrity, and ChatGPT  Debates surrounding the integration of GenAI, particularly ChatGPT-3, in education, especially distance education, centre on ethical concerns. Oppenheimer (2023) argues that while AI systems may increase access to information, concerns about academic integrity existed before, and AI does not fundamentally alter these dynamics. Tlili et al. (2023) propose an ethical and interactive integration of GenAI systems to enhance the development of twenty-first-century competencies. Identifying these competencies stems from addressing what Weinberger (2007) terms ‘a new digital disorder’. Dede (2009) sees the development of twentyfirst-century skills as a response to ‘disorderly’ knowledge co-creation and sharing. As technology disrupts learning, especially in the post-COVID world, a holistic appraisal of stakeholders’ experiences in teaching and learning is necessary in the ODeL context. The impact of technology disruption is evident during learning assessments, particularly in plagiarism. Jones and Sheridan (2015) note that plagiarism affects student equity and diminishes qualities aligned with academic voice. The incorporation of GenAI technologies like ChatGPT in student resources necessitates a reevaluation of assessment strategies. Oppenheimer (2023) suggests focusing on integrity training, cultivating a healthy campus culture, and reducing incentives to cheat as effective strategies against academic dishonesty. However, ChatGPT’s reliance on various sources and students’ ability to discern source credibility raise concerns about its reliability as an educational resource. OpenAI’s President, Brockman (2023), acknowledges the system’s “emergent (unanticipated) capabilities,” making it volatile in its current form. As debates persist, careful consideration of the ethical integration of GenAI, assessment strategies, and the impact on academic integrity in distance education is crucial. Sullivan et al. (2023) have further directed such debates toward how developing policies related to the use of GenAI would take time and be directly influenced by a longitudinal evaluation of how such technology is used or misused (p. 35).  Generative AI’s influence on academic voice in distance education  As indicated above, academic dishonesty impacts the ability to develop an academic voice. McQuillan (2021) describes voice as being founded on “original ideas and thoughts and [that] it is used to establish credibility” within the academic context (p. 32). She continues to emphasise that originality in thinking is fundamental to developing an academic voice (McQuillan, 2021). McQuillan, therefore, equates academic voice with originality and responsibility—a connection also noted by Thompson (2012, p. 121). In terms of the concerns regarding AI’s potential challenge to originality and responsibility, Holmes et al. (2023) highlight four key concerns: information bias, AI’s capacity to make autonomous decisions, which could impact outcomes quite severely, privacy in the exchange of personal data, and the “potential [for AI] to be used for malicious purposes” (p. 97). Concerning the development of academic voice among undergraduate students, exposure to information mediated by GenAI systems such as ChatGPT means that students need to be taught better and more efficient ways to discern between credible and non-credible information. Therefore, stakeholders in the learning process within the ODeL context cannot deny that an additional nonhuman stakeholder has emerged. In response, Holmes et al. (2023) propose a new stakeholder framework that acknowledges AI as centrally influencing the interaction between students, teachers, and institutions (p. 101). However, they are cautious in asserting how GenAI’s influence—its algorithms and programmingwill be enacted in the future (Holmes et al., 2023).  This framework is relevant to the ODeL context in that much of the interaction between teachers, students, and institutions is mediated by technology. Mediation calls into question the capacity of students to develop an authentic academic voice through AI systems like ChatGPT or whether that voice is vulnerable to manipulation. The higher instances of plagiarism among students suggest that the development of an authentic academic voice is under threat. However, Rudolph et al. (2023) assert that the perceived threat may be because of a “bureaucratic inertia” that is struggling to adapt to the capacity of students to engage with GenAI (p. 354). Rudolph et al. (2023) further recommend that GenAI has the capacity to enhance the facilitation of students’ curiosity, experimentation, and collaboration as a learning outcome. However, traditional assessment policies do not fully embrace this measure of student learning. Ifelebuegu (2023) comments on the debate between authentic and AIassisted assessment, which is more complicated in online learning contexts. Student voice, as implied by Ifelebuegu (2023), is threatened when the dialogic potential between students and GenAI tools is not employed to enhance critical thinking:  The advent of AI chatbots has introduced a unique challenge to the integrity of online assessments, leading educators to reevaluate traditional assessment methods. As we navigate this landscape, it is clear that assessments must evolve to maintain their authenticity and effectiveness in promoting meaningful learning. This exploration has underscored the importance of reshaping assessments to value higher-order cognitive skills, problem-solving, creativity, and collaborative abilities. Authentic assessments such as open-ended tasks, project-based assignments, collaborative assessments, and portfolio-based assessments not only align with these values but also pose a significant challenge for AI chatbots to replicate or assist in, thereby preserving their integrity. AI may also aid assessment rather than just being a danger (Ifelebuegu, 2023, p. 389).  From a student-centred perspective, Chan and Hu (2023) note the challenge that AI presents to the development of holistic competencies, such as the capacity for creative and critical thinking, which inform academic voice (p. 11). Baker and Smith (2019) contextualise the incorporation of GenAI in education as student-centred and further assert the need to consider two other key stakeholders in evaluating how GenAI is incorporated: teachers and systems or administrators. Ahmad et al. (2024) noted that each stakeholder has differing views of the benefits and threats presented through GenAI. While Ifelebuegu et al. (2023) note  the benefits that include assisting with academic writing, facilitating personalised learning, and interdisciplinary education, they also highlight the threats of information bias and misinformation, plagiarism, and an overreliance on technology at the expense of critical thinking development in students.  Using the technology acceptance model for AI  The technology acceptance model (TAM), developed by Davis (1989; 1993), serves as a lens to explore the factors influencing the acceptance and usage of technology. In this context, external factors represent the features of ChatGPT, assessing its adaptability to personalised learning experiences and its potential to reshape assessment methodologies in distance education (Davis, 1989). The study explores cognitive responses (Davis, 1989), mainly the perceived ease of use and usefulness of ChatGPT. It examines the effortlessness of interaction and how much it enhances academic experience in a distance education context. The affective response (Davis, 1993), captured by attitudes toward using technology or behavioural intentions, highlights how students and lecturers perceive and intend to utilise ChatGPT. The outcome reflects the active integration of ChatGPT into academic activities (Davis, 1989). TAM outlines a three-stage process for technology acceptance, as we illustrate in Figure 1 below.  Figure 1. The technology acceptance framework (adapted from Davis, 1989).  External factors trigger cognitive responses, such as perceived ease of use and usefulness, leading to an affective response and influencing user behaviour. The model predicts behaviour based on perceived ease of use, perceived usefulness, and behavioural intention. Affective responses, particularly attitudes toward behaviour, play a crucial role in determining the likelihood of technology adoption. While perceived usefulness directly affects one’s use behaviour, perceived ease of use indirectly influences it by supporting the effect of usefulness. If an application is perceived as easy to use, it is more likely to be considered useful, stimulating technology acceptance (Davis, 1989, 1993). Applying TAM to the study provides a structured framework for analysing ChatGPT’s influence on distance education (Davis, 1989). It enables an examination of how external factors impact cognitive responses and influence the acceptance and integration of ChatGPT into the context under study (Davis, 1989). The model is integral in addressing concerns about academic integrity by assessing how perceived ease of use and usefulness influence attitudes and intentions, thus contributing to a critical understanding of the ethical considerations surrounding ChatGPT’s application in education (Davis, 1989). Furthermore, TAM facilitates an exploration of the affective responses and reveals insights into how students perceive ChatGPT’s role in shaping their academic voice and originality.  Methodology  Research approach and design  This study employed a qualitative case study research approach (Baskarada, 2014) to explore the transformative influence of ChatGPT in distance education. A case study design was deemed appropriate for its ability to provide an in-depth understanding of the phenomena within its reallife context. The study focused on the Department of English Studies at an ODeL university in South Africa.  Research context and population  The research was targeted at first-year students enrolled in an academic writing module. The decision to focus on first-year students stems from their diverse backgrounds that reflect a wide range of linguistic, social, and cultural perspectives. However, challenges, such as limited access to technology, highlight the need for tailored support. Moreover, a digital divide among lecturers highlights the complexity of addressing these issues within the department. This module reflects a diverse student body with varying linguistic, social, and cultural backgrounds. Notably, many students faced challenges such as limited access to technological tools and diverse personal responsibilities, including part-time or full-time work and caregiving responsibilities. The lecturers who teach first-year students in the department, spanning various age groups, indicate a digital divide within the teaching staff.  Population, sampling, and research instruments  The population for this study comprised the entire cohort of 14,000 first-year students enrolled in the Academic Writing module under study. The sampling strategy was purposive, targeting ten first-year lecturers for one-on-one semistructured interviews to address the first research question. In addition, five administrative staff members were selected to respond to the second research question through openended email evaluation questions. For the third research question, 20 students who spoke English as an additional language (EAL) were invited to participate in a Microsoft Teams focus group discussion (FGD).  Data collection  The study was conducted during the second semester of 2023, from August to December 2023. Ten lecturers were interviewed individually via e-mail, five administrative staff responded to open-ended email evaluation questions over two weeks, and a Microsoft Teams FGD involved 12 out of the 20 invited students, which lasted approximately 1.5 hours. Thematic analysis was used to analyse the collected data,  which were organised according to the following themes:  How ChatGPT technology influenced and transformed distance education.  The impact of ChatGPT on academic integrity in distance education.  How ChatGPT affects students’ voices in distance education.  •  •  •  Ethical considerations  Informed consent was obtained from all participants, ensuring their voluntary participation. Participants were assured of confidentiality, and the module name, the name of the university, and all participants were anonymised in the presentation of findings to protect their identities. Lecturers in the study are called L1, students S1, etc., and administrative officers, A1 and so on. The study adhered to ethical guidelines, and approval was obtained from the relevant institutional ethics review board at the university under study. Moreover, participants were informed of their right to withdraw from the study at any point without consequences.  Findings and discussion  How ChatGPT technology influenced and transformed distance education  The responses from lecturers regarding the impact of ChatGPT were limited, with only two of the targeted ten lecturers providing critical insights in this regard. Both responses were sceptical of the effects of ChatGPT on and/ or transformed distance education.  Perceived negative impact on academic integrity  With literature noting the impact of academic dishonesty on voice and the ability to think critically and creatively (Jones & Sheridan, 2015), both lecturers emphasised the negative impact of ChatGPT on academic integrity. L1 responded to the open-ended evaluation question by stating, “Unfortunately, in my experience, it has made academic dishonesty more rife”. L1 drew on their experience in assessing student work to provide examples of the impact of ChatGPT on student performance:  We have found students to not only have fed our questions into it and submitted the answers it provided (to varying levels of soundness; some of the AI answers are decent, some are nonsensical and only barely relevant to the question), but we have also found students to have shared these answers amongst each other in the distancebased context, with the result being that a notinsubstantial number of students submitted the exact same AI-generated answers.
This view is echoed in L2’s response, where they observe that “ChatGPT perhaps intensifies what Google and the internet have long established: the sense that knowledge and understanding are immediately available and accessible through the provision of the appropriate search terms or application of the correct technique”, thereby affecting critical and creative thinking. Authentic assessment as measuring independent, critical thinking is, therefore, compromised according to lecturers’ perspectives, an assertion supported by Bozkurt and Sharma (2023). However, reliable and actionable strategies to mitigate this are not indicated. The responses offered by lecturers contradict TAM in that positive acceptance is countered by intense skepticism and heightened caution. In reviewing the two responses, they are contextualised within the scope of older, more established systems of assessment encountering new disruptive forms of information access. This is echoed in the concerns Chan and Hu (2023) expressed regarding the threat generative AI poses to the development of holistic critical competencies.  Teaching and learning transformation within ODeL contexts Though L1 did not acknowledge the need for novel approaches to teaching and learning, and in particular, assessment, L2 was more open to considering how ChatGPT’s introduction into the teaching and learning context requires a shift in strategy. They observe the following:  My sense is that it’s transforming, rather than fully transformed, so I don’t think I can provide a definitive answer. It has shifted my sense of how I should approach my teaching. I feel a heightened need to guide students to the sense that they themselves are vital to what we call under blanket terms ‘learning,’ ‘scholarship,’ ‘research’, etc. – to help them develop a sense that the point of the exercise is a transformation in the learner, not the retrieval or repetition of what is already known.  L2 is introspective in terms of demonstrating awareness that the shift that is required in response to the disruption of GenAI cannot be levied on the student but should be guided by new teaching and learning practices, including assessment practices: “I’m experiencing serious doubts about assessment practices in this context—and even about the very principles which underlie assessment. This is a ‘crisis’ (a moment of decision?) not unique to the distance learning environment.” The lecturer demonstrates the space that ODeL now occupies in terms of its response to disruptionin this case, the advent of GenAI—and the need to adopt new thinking practices.  In this sense, real-world concerns about GenAI’s negative impact on existing teaching and learning practices encounter a positive call to transform teaching and learning practices to future-proof higher education in ODeL contexts. However, the general view is one of despondency in the face of a new challenge, making transformation seem insurmountable.  The impact of ChatGPT on academic integrity in distance education  The responses from the five administrative staff members varied, which reflected a spectrum of perspectives on the impact of ChatGPT on academic integrity in distance education.  Perceived positive impact on skills development  An administrator emphasised ChatGPT’s potential to contribute to critical thinking and independent research skills and portrayed it as a facilitator rather than a replacement for essential academic skills. A1 noted that “ChatGPT can act as a tool to promote critical thinking and independent research skills. I think it challenges students to use information critically, which makes learning more exciting.” The emphasis on promoting critical thinking and independent research skills suggests that A1 sees ChatGPT as a facilitator rather than a replacement for these essential academic skills. The findings do not corroborate with scholars such as Rudolph et al. (2024) and Popenici et al. (2023), who caution against the blind adoption of new technologies in education and highlight the ideological implications and challenges posed by the integration of AI. While Rudolph et al. (2024) and Popenici et al. (2023) rightly emphasise the ideological impact and challenges of adopting AI, it is essential to recognise that the area of educational technology is multifaceted, and its impacts can vary significantly depending on the context, implementation, and the specific technology in question. The findings, however, resonate with the idea that AI technologies can supplement human capabilities and provide additional resources and support rather than diminishing the role of students’ independent thinking (Bozkurt & Sharma, 2023). This aligns with TAM, where positive perceptions of a technology’s usefulness and ease of use influence its acceptance. This perception of usefulness can shape positive attitudes and behaviours toward integrating ChatGPT in educational contexts. A1’s positive outlook aligns with the literature suggesting that AI technologies, including ChatGPT, can enhance critical thinking and independent research skills (Mollick & Mollick, 2022).  Concerns about authenticity and originality  In contrast to A1, A2 expressed reservations that echo concerns in the literature about potential overreliance on AI-generated content challenging the authenticity and originality of students’ work. He argues,  The risk of students relying too heavily on AIgenerated content is concerning. It challenges the authenticity of their work and raises questions about the originality of their ideas. We have seen such instances this year where plagiarism was rife in assignments. This then affects us all, from lecturers to the students.  The acknowledgement that there have been instances of plagiarism raises immediate red flags about the tool’s impact on the authenticity and originality of students’ work. A2 argued that it is concerning that students use AI to plagiarise in their assessments. This calls into question students’ originality, their learning, and the integrity of the university. This aligns with existing literature highlighting AI technologies’ challenges to academic integrity and the need for a vigilant approach (Jones & Sheridan, 2015; Maphoto et al., 2024; Oppenheimer, 2023). In addition, Lindgren (2023) stresses the importance of critical analysis in questioning AI innovation's social and political implications, particularly in education. These critical perspectives challenge the notion that ChatGPT facilitates skills development and urges lecturers and institutions to consider the broader ethical implications and societal consequences of AI integration in education. Moreover, Chaka (2024) argues that contemporary AI detectors and traditional anti-plagiarism tools should be combined with human reviewers and raters to differentiate between AI-generated and humangenerated text. This aligns with broader concerns in the literature about the potential disruption of traditional learning paradigms, such as overreliance on AI hindering critical thinking, bias and access disparities, and the need for comprehensive strategies to mitigate risks (Bozkurt & Sharma, 2023). This finding also calls for lecturers and stakeholders in HEIs to educate students on the responsible and ethical use of AI. If students are not taught how to use AI responsibly and ethically, we must expect plagiarism and unethical AI usage from students who are not confident with writing using their voices.  Importance of safeguards and transparency  Administrators introduced a critical perspective and emphasised the need for assessment safeguards and proactive university guidance regarding ChatGPT’s use. A3 suggested:  The university should guide us on how to deal with AI when it comes to assessments. There are talks of lecturers using it in assessments, but if this is to happen, we must ensure that students use it wisely. But I think the university needs to take a stand.  A3 suggested that the university should proactively guide lecturers on how to incorporate GenAI in assessments. While there are discussions about allowing lecturers to use GenAI in assessments, A3 highlighted the need to establish clear guidelines. Like A2’s perspective, A3 raised concerns about the potential misuse or overreliance on AIgenerated content but also suggested a focus on ensuring a smooth integration process to promote the acceptance and effective use of ChatGPT (Davis, 1989; Venkatesh & Davis, 2000). The perceived ease of use of ChatGPT, as highlighted by A1 and A3, may contribute to a positive attitude among administrative staff members. This ease of use can impact their willingness to adopt ChatGPT in academic assessments. The emphasis is ensuring that students view ChatGPT as a supplementary tool rather than a replacement for their ideas. This aligns with the call for faculty development programmes and workshops to guide lecturers in effectively integrating AI technologies into assessments and ensure that students use them as supplements rather than replacements for their  ideas (Bozkurt & Sharma, 2023). A4 and A5 further argued for the importance of transparency in using ChatGPT for assessments. They noted that students should be educated about the role of ChatGPT, its limitations, and the significance of their independent contribution to academic work. A5 argues, “Transparency is key. Students should be taught about the role of AI in assessments”. This approach aims to create awareness of the ethical use of ChatGPT in HEIs and a balanced understanding of the technology’s role in the learning process. This corroborates with TAM’s emphasis on clear communication and education influencing technology acceptance (Davis, 1989). The stress on transparency also resonates with the principles of integrity and responsible AI usage (Holmes et al., 2023).  How ChatGPT affects students’ voices in distance education  Changing perspectives on student voice and AI integration  Integrating ChatGPT into distance education introduces a transformative force beyond technological augmentation (Chugh et al., 2023). This change in thinking prompts a reevaluation of pedagogical norms, particularly in terms of its impact on student voices and authorship (Ali et al., 2023). According to one student: “It’s already tough because my home language is isiXhosa. I don’t think a computer can understand what I’m trying to say better than a person” (S1). S1’s hesitation about relying on AI due to language barriers and concerns about the computer understanding their thoughts reflects an initial skepticism that aligns with the broader literature on the apprehension towards AI in education (Chugh et al., 2023; Popenici et al., 2023; Rudolph et al., 2024). This skepticism is crucial to perceived ease of use, as students might find it challenging to utilise AI tools effectively. S1’s concerns highlight the importance of addressing the ease with which students can interact with ChatGPT and emphasise the need for user-friendly interfaces and training. S2 expresses concerns about the potential impact of ChatGPT on their writing style and individual voice. “It might be a shortcut, you know? What if it...makes me sound less like me?” (S2). The fear of losing personal identity in their writing and the possibility of negative assessment consequences reflect worries about maintaining authenticity and uniqueness in academic work. S2’s concern about ChatGPT as a ‘shortcut’ reflects perceived complexity (perceived ease of use). Their worry about the tool changing their writing style emphasises consideration of usefulness (perceived usefulness). The fear of sounding ‘less like me’ and potential assessment failure indicate emotional aspects influencing attitudes and behavioural intentions, aligning with TAM principles.  Student voice enhancement through AI  As ChatGPT promises to transform online assessment methodologies (Naidu & Sevnarayan, 2023), the second subtheme explores students’ perspectives of AI as a supportive tool. However, concerns about potential complacency in students’ efforts necessitate a careful examination of the role of AI in education.

If AI can help me catch mistakes and suggest improvements, I’m all for it. It could save me a lot of time and stress, especially when deadlines are looming (S6).  I worry that relying too much on AI might make me lazy. I want to make sure that I do the work for me? (S11).  The contrasting views among students highlight the need to assess the implications of AI integration critically. S6’s perspective aligns with the concept of perceived usefulness in TAM, where AI is viewed as a time-saving tool for error detection and improvement suggestions (Davis, 1989). This positive outlook resonates with the literature on the transformative potential of AI in enhancing efficiency and task performance in education (Rasul et al., 2023). On the other hand, S11’s concern about overreliance on AI and potential complacency is consistent with discussions on the ethical dimensions of AI integration in education (Oppenheimer, 2023; Popenici et al., 2023; Rudolph et al., 2024). This resonates with the technology acceptance model (TAM). This model illustrated how attitudes and potential behavioural intentions are critical in technology acceptance (Davis, 1993). The apprehension expressed by S11 aligns with studies that emphasise the importance of responsible implementation to mitigate concerns related to dependency on AI (Cotton et al., 2023). With its emphasis on perceived ease of use and usefulness, TAM provides a critical understanding of students’ attitudes toward AI and emphasises the need to consider affective responses and intentions. The notion of ‘perceived ease of use’ may be influenced by factors such as prior experience with technology, digital literacy, and socio-economic status. It is pertinent to acknowledge that students’ readiness to accept and incorporate ChatGPT into their academic activities is significantly influenced by the perceived ease of use (Davis, 1989). Furthermore, the focus on individual attitudes and intentions in TAM overlooks the structural and systemic factors that shape the adoption and implementation of AI in education. A more critical approach would consider the political economy of AI, the role of neoliberalism in shaping education policy, and the impact of AI on the labour market and the future of work.  Striking a balance between authenticity and learning  The third subtheme explores questions about the impact on academic integrity and points to the need for ethical considerations in the integration of ChatGPT.  I’m worried that if I use AI too much, it might feel like I’m not really learning. I want to know I passed on my own strength (S7).  How do I know if the suggestions from AI make my writing better or just more ‘correct’ in a technical sense? (S8).  S7’s apprehension about overreliance on AI speaks to the balance needed between technological support and preserving learning experiences. This concern, reflected  in broader discussions on the challenges of maintaining authenticity in AI-assisted education (Holmes et al., 2023), aligns with TAM’s concept of perceived usefulness. The concern centres around the potential impact on agency in the learning process and emphasises the need to carefully integrate AI tools to enhance learning outcomes while preserving students’ sense of accomplishment and reducing transactional distance (Davis, 1993; Moore, 2013). However, it is crucial to critically examine the power dynamics at play, as the increasing reliance on AI may perpetuate existing inequalities and reinforce dominant epistemologies. Moreover, emphasising efficiency and productivity in AIdriven learning environments may lead to a narrow focus on technical skills, neglecting critical thinking and creativity. Similarly, S8’s inquiry into the effectiveness of AI suggestions in improving writing quality centres on the authenticity of the learning experience. This corroborates with literature highlighting the evaluation of AI-generated content and its compatibility with individual writing styles (Perkins, 2023). However, it is essential to interrogate the notion of authenticity in the context of AI-assisted learning and consider the potential for GenAI to both enable and constrain student agency. The literature foregrounds the potential benefits of AI in reshaping traditional paradigms (BaidooAnu & Ansah, 2023) and personalising learning experiences (Bozkurt & Sharma, 2023). However, the concerns raised by students align with the ethical considerations highlighted in the literature, such as the potential impact on academic integrity (Perkins, 2023) and the need for discernment in utilising AI resources (Holmes & Porayska-Pomsta, 2023). These concerns are technical and political, requiring a critical understanding of the intersections between technology, power, and pedagogy.  Limitations  While this study provides insight into the transformative influence of ChatGPT in distance education, several limitations should be considered. Firstly, the focus on firstyear students in a single department at an ODeL university in South Africa may need to be revised to include the generalisability of findings to other educational contexts. In addition, the reliance on qualitative methods, such as interviews and focus group discussions, may introduce bias or subjectivity in data collection and interpretation. Finally, purposive sampling may result in a non-representative sample and potentially overlook diverse perspectives from participants.  Conclusion and recommendations  Within the scope of our study, several key findings emerged. Lecturers tended to be more pessimistic and cautious about the impact of ChatGPT on academic integrity. Unlike lecturers, administrative staff and students adopted a more transformative view of ChatGPT’s potential in enabling learning, though it requires careful management. In filtering all responses through the TAM lens and orientating them withintheODeL context,it is evidentthatstakeholderattitudes towards the impact of ChatGPT on academic integrity and academic voice are not fully aligned in purpose. This has created barriers to acceptance because of the prescriptive nature of the current teaching and learning context of ODeL institutions. However, such institutions present the greatest potential for transformation because of their orientation toward digital teaching and learning engagement. This may mean open conversations between stakeholders about academic integrity, which was flagged as a stakeholder concern to varying degrees. The discrepancy between the skepticism towards ChatGPT’s ability to negatively impact academic integrity and the positive attitudes towards its ability to encourage more confident student interaction with learning materials compromises teaching and learning as authentic to the context within which it is enacted. This discrepancy feeds into an already-existing debate between authentic and AI-assisted assessment (Ifelebuegu, 2023). The emphasis on traditional assessment methods not only undermines student voice but also perpetuates a culture of standardisation, which is antithetical to the principles of authentic assessment. If lecturers rethink assessment strategies, they could create opportunities for students to engage in meaningful, self-directed and/or collaborative learning that values their unique voices and diverse sociocultural perspectives. The artificiality of GenAI is disrupting the academic values of integrity and voice, highlighting the inadequacy of traditional assessment to facilitate new forms of dialogic and collaborative learning.  The findings in this study demonstrate an urgent need for HEIs to rethink their approaches to teaching and learning in the age of GenAI. To encourage the power of GenAI in enabling students to utilise their voices, ODeL institutions should encourage open conversations, integrate GenAI into teaching and learning, and guide students with the technology towards building a community of practice. Lecturers can implement GenAI into their teaching through student-led discussions, reflective journals, peer review, critique, and student-generated questions, which promote ownership and exploration of topics. AI should not be used to elicit fearmongering in education but can be used as a tool to help students use their voices to generate prompts, generate ideas, improve their writing, edit their submissions and provide constructive critical feedback on peer work. In addition, lecturers can create multimodal assignments, allowing students to express themselves in diverse formats that reflect critical and creative thinking. Lecturers should create an inclusive and interactive space where students feel comfortable sharing their thoughts and ideas and develop critical thinking and communication skills even further. This is especially important with GenAI, as it enables students to utilise the potential of AI tools to support their learning while maintaining their unique voices and agency as distinct from AI. Most importantly, lecturers should be trained to teach students responsible and ethical use of GenAI and create a culture of digital literacy and accountability. In doing so, we can equip students with the skills to benefit from AI’s potential while mitigating its risks and ensuring they become informed and ethical users of these powerful technologies. However, this cannot be fully realised without the collaborative input of all stakeholders—students, lecturers, and administrators—in negotiating new systems of teaching and learning with stronger lecturer buy-in in coming alongside students. This will require lecturers to upskill or risk becoming obsolete within the current and  future AI-infused HEI context. Moreover, open educational practices within the context of HEIs in the Global South have the capacity to promote themselves as democratised centres for transformative thinking as they utilise a new form of authentic teaching, learning, and assessment.



