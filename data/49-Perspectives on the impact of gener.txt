Perspectives on the impact of generative AI on early-childhood development and education

Abstract
Generative artificial intelligence (GAI) is rapidly becoming ubiquitous in many contexts. There is limited scholarship, however, in the fields of Developmental Psychology and Early Childhood Education exploring the implications of generative AI for babies and young children. In this Perspectives piece, we discuss potential use cases, opportunities, and risks for the application of AI in early childhood. Our insights are informed by extensive discussion with stakeholders and by desk research carried out in our roles as academics and analysts in a social innovation foundation. Our aim is to stimulate nuanced and informed discourse on the topic of generative AI in early childhood that can inform innovation in both research and practice.

1 INTRODUCTION
Discourse about the role of technology in relation to child development and education is hardly new (Doroudi, 2022; Papert, 1980), however, the speed and scale of recent technical advances in the field of artificial intelligence (AI) bring a new urgency to academic debates (Bahroun et al., 2023). As recently argued by Edwards (2023), it is not sufficient for those working in early childhood research and practice to simply be aware of terminology; we must understand the impact of new technologies and their integration with diverse knowledges and practices. In the case of generative artificial intelligence (GAI), this includes understanding how the technology is used in practice (Luo et al., 2024), as well as the opportunities for innovation and change (both good and bad) that it presents.

This Perspectives paper is an interdisciplinary collaboration between experts in technology futures, data science and developmental psychology. Our collective mission is to create innovative solutions to the persistent problem of the impact of socioeconomic inequalities upon child development in the early years of life (Nesta, 2023; PEDAL, 2022). We argue that GAI technologies are at a key juncture where there is potential to either entrench or ameliorate the effects of inequalities upon children's outcomes. Our aim in this paper, therefore, is to address a provocative question to our communities: How will YOU shape the ways in which the GAI revolution transforms research and practice in early childhood education (ECE)?

2 WHAT IS GENERATIVE AI?
GAI algorithms learn from vast datasets to create new content such as text, images, music or video. A major category of GAI algorithms are large language models (LLMs), which can generate high-quality text to engage in conversation, answer queries, and even perform complex language tasks. GPT-4, a state-of-the-art LLM developed by the US-based company OpenAI, has been shown to achieve high performance on various benchmarks such as commonsense reasoning and science exams, and it can even pass a simulated bar exam (OpenAI, 2023a).

The release of ChatGPT—a general-purpose LLM-based chatbot—by OpenAI in November 2022 was an inflection point in the mass adoption of GAI, showing one of the fastest historical adoption rates of a digital product and reaching an estimated 100 million monthly active users in 2023 (Bahrini et al., 2023). Other major technology companies promptly followed OpenAI by releasing their own LLM-based chatbots such as Bard (Google) and Claude (Anthropic).

LLMs generally work by predicting the next word given the previously generated words (within a context window of a limited length) and the instruction prompt written by the user. Such an approach does not specifically involve planning and therefore is limited in terms of the complexity of tasks it can tackle. Nonetheless, even at this stage of development, this technology is expected to continue developing rapidly. The potential economic impact of GAI has attracted substantial investment with an estimated USD 14.1 billion invested in GAI startups in the first six months of 2023 (CB Insights, 2023). Engineers are making GAI systems multi-modal, such as the GPT-4 with vision (GPT-4 V) which enables the LLM to answer questions about images (OpenAI, 2023b). A burgeoning ecosystem of open-source GAI models will also help propel research in this area (Zhao et al., 2023).

3 USE CASES
To frame our perspectives on how this technology might influence early child development and education, we mapped the landscape of possible use cases related to ECE and care. We identified more than 30 use cases across four major categories: teaching, operations, family support, and content (see Figure 1). We consider each use case category in turn.

Details are in the caption following the image
FIGURE 1
Open in figure viewer
PowerPoint
Categories of use cases for generative AI in early childhood education.
3.1 Teaching: Creative tools for supporting teaching
Our first use case category concerns support for educators. ECE practitioners have to remain creative and energized in the face of a substantial workload. LLMs could help practitioners with preparation and by providing creative support. For example, algorithms can produce lesson plans, generate activity ideas, design games or write stories (Butler Diaries, 2023; Hernandez, 2023; Stathoulopoulos, 2023). Moreover, the flexibility of LLMs to respond to instructions and feedback allows the practitioner to tailor these outputs to an individual child's interests and developmental level; thus fostering curiosity, motivation and engagement. This could also help teachers in creating culturally relevant learning materials reflecting the diversity of children's backgrounds (Baskara, 2023).

Some educators have even taken a step further and trialled GAI voice chatbots which children can interact with in a preschool setting (Lee, 2023). While this technology is not mature and tested enough to be widely deployed in schools, this case exemplifies the use of GAI as a conversational agent for young children (Luo et al., 2024). Responsibly developed, interactional technology could help solve the problem of ‘passive’ technology use and promote the contingent interactions that are essential for child development.

3.2 Operations: Easing the administrative burden
Streamlining administrative tasks is another promising avenue for applying GAI. Early childhood educators have consistently noted the challenging amount of paperwork between lesson or activity planning, teacher-parent communication and record-keeping (Boyd, 2013; PACEY, 2015; Thorpe et al., 2018). LLMs could ease some of these burdens, by supporting with drafting parent communication messages, newsletters, enrollment forms, meeting agendas, parent surveys and more (Waldman, 2023). As the usage of and investment into digital platforms for managing education and care settings increases (Hatzigianni et al., 2023; Kanders & Newman, 2023), developers of these platforms will likely also include GAI in their offer, thus paving the way for a widespread adoption of this new technology. For example, the biggest early-years software provider in the UK has already included an AI-powered assistant for writing newsfeed posts, observations, assessments and two-year checks in their platform (Famly, 2023).

3.3 Family support: A caregiving co-pilot?
Connections between ECE and care settings and the ‘home learning environment’ are increasingly recognized as significant to early child development. GAI could bolster familial involvement in the educational journey. Creative support such as coming up with personalized activity ideas could also be useful for parents, and help them to identify new ways to engage their child that align with the learning they experience in other contexts. Researchers have been trialling GAI to support home learning and increase parents' confidence in helping their children (Hadi Mogavi et al., 2024).

More broadly, supporting families with evidence-based advice through apps and chatbots is an active area of research and development (Davis et al., 2017; Entenberg et al., 2023; Kanders et al., 2022a, 2022b; Lachman et al., 2023). For example, Etenberg et al. (2023) trialled micro-interventions in Argentina using a chatbot to teach parents how to praise their children. A randomized controlled trial is underway in South Africa to test a chatbot for promoting playful parenting and preventing violence against children (Lachman et al., 2023). GAI could support the development and potentially the user experience of such chatbots, by making it easier and more cost-effective to adapt evidence-based caregiving advice to different audiences, contexts and conversational styles.

Anecdotal accounts also suggest some parents are already trying out LLM-based tools like ChatGPT to support them in household tasks such as planning meals or scheduling daily activities (Nwaogu, 2023). The private sector is developing apps such as an “AI co-pilot for parents” which uses LLMs to streamline the planning of household tasks (Milo, 2023). If such tools can significantly reduce caregivers' mental load and free up time, they might indirectly contribute to a better home learning environment.

3.4 Content: Facilitating the production of engaging and interactive content
GAI can speed up the creation of engaging and personalized image, video and audio content, reducing the associated costs and effort. For example, tools like Midjourney allow users to generate high-quality images in various styles from a text description in less than a minute. In early 2024, OpenAI publicized a new state-of-the-art text-to-video model that can generate minute-long videos at an unprecedented quality that would otherwise take teams of professionals hours and days of effort (Brooks et al., 2024). While it is still a major challenge to control the fine visual details of such generations, a recent study by Grassini and Koivisto (2024) suggests that adults might even prefer AI-generated image content—as long as they think it was made by humans (we are not aware of similar studies with children yet).

While the use of GAI for creative applications has raised criticism due to concerns around the quality of the outputs, copyright and impact on creative professionals, GAI has already found commercial uses, for example, for crafting children's books (Popli, 2022), creating personalized stories with the child as the main character (Shrivastava, 2022) and generating voice narrations (Typecast, 2023).

Video games are another area with high expectations regarding the impact of generative AI (Gwertzman & Soslow, 2022; Lee & Lee, 2023). Industry executives believe that within 5–10 years AI could manage more than 50% of game development, improving the quality of games and delivering them more quickly (Christofferson et al., 2023). There are reports of production companies already adopting generative AI to, for example, generate 3D assets and reduce the costs of game concept creation by more than 50% (Levy-Weiss, 2023).

If GAI is successful in speeding up software development and creation of video games, we might see an upsurge in innovative educational tools and games that can promote aspects of child development. However, it is yet to be seen if GAI will improve the quality of toddlers' screen time.

4 PERSPECTIVES FOR THE PSYCHOLOGY COMMUNITY
At their best, these GAI use cases might help make ECE and care more personalized, engaging and tailored to individual developmental profiles, while also easing the workload for caregivers and educators. This is, however, a new and rapidly developing technology, which does not come with a “user manual” and also poses risks.

We therefore believe that the developmental psychology research community should play an active role in shaping, exploring and evaluating the impact of GAI. There are rich opportunities for cross-disciplinary research and in the following, we outline some of these avenues.

4.1 Open and responsible experimentation
Researchers should collaborate with ECE practitioners and caregivers to explore the utility of GAI tools for different tasks, and publicize the results to build shared understanding across the sector. Given the rapid pace of development of GAI, this work would benefit from an iterative, design-thinking informed approach, where insights and best practices are shared frequently with the wider community in the form of case studies and short reports. The wide accessibility of GAI means that developmental psychology as a discipline may soon have access to unprecedented amounts of data about the contexts and details where GAI is used in children's everyday lives. This could yield new insights into child development, leading to new research directions.

At the same time, researchers and practitioners should be mindful of the limitations of GAI and protect children from potential harms. There is presently no strong guarantee of safety or quality of the outputs generated by any LLM. Generative models use a level of randomness in their responses that helps them create human-seeming content, but this also makes them unpredictable. While GAI can generate text that appears plausible, making it easier for users to believe, responses can be factually incorrect or nonsensical and on rare occasions offensive (Alkasissi & McFarlane, 2023; Rawte et al., 2023). Moreover, there is also a risk of perpetuating existing biases and stereotypes. These tools are trained using large amounts of content from books, social media and the wider internet, which means that they could have embedded within their ways of working all of the biases that exist in human thought (Navigli et al., 2023). To mitigate these issues, there is ongoing research to ensure LLMs better understand and reflect user instructions, preferences, and intrinsic values (Wang et al., 2023). Some researchers are also experimenting with using public participation and deliberation approaches to decide upon the desired values embedded in GAI in a democratic way (Ganguli, Huang, et al., 2023).

In the context of ECE, LLMs could be made more fit-for-purpose by a range of engineering approaches, from retrieval-augmented generation to fine-tuning (model refinement) using curated data and specialist input which reflects safe and verified education curricula and best practices. The large array of open-source LLMs (Zhao et al., 2023) also creates the conditions for open experimentation and sharing of results.

Finally, there is also the perhaps more complex question of what values educators would like to embed in educational GAI. For instance, GAI-based systems might prioritize creativity and critical thinking or, conversely, encourage compliance. Moreover, it is important to consider the stances GAI might adopt regarding critical societal issues such as social justice, disparities, or systemic racism. Frameworks such as Su & Yang's IDEE Framework, which encourages educators to Identify Desired Outcomes, Determine the Appropriate level of Automation, Ensure Ethical Considerations and Evaluate Effectiveness could be useful in providing early childhood educators with a broad structure for thinking about and acting upon these issues in a systematic way (Su & Yang, 2023).

4.2 Rigorous evaluation
Assessment of the benefits of GAI-based tools and interventions such as chatbots will be critical for their safe deployment in ECE and care. As promising use cases emerge from early experimentation, researchers will need to support the sector by conducting rigorous evaluation of GAI-based interventions.

There are numerous emerging approaches for evaluating various aspects of LLMs such as user preference, accuracy, fairness and potential for misuse (Ganguli, Schiefer, et al., 2023). Each of these approaches, however, comes with its own set of challenges and developing LLM evaluation methods is an active research area. An important future direction will be to support the industry to engage with educators and researchers to ensure these tests have contextually relevant validity.

It will be even more important to evaluate the impact of GAI-based tools on specific education and parenting outcomes. Such as, whether the use of GAI chatbots in an educational context results in better attainment, higher job satisfaction, or time spent less on administrative tasks and more on interaction with children.

4.3 Monitoring and facilitating adoption
Although GAI is accessible to millions, there is, however, a long way to go before this technology gains widespread traction. For example, a representative survey of the general US population from August 2023 showed that only around 18% of adults have ever used ChatGPT (Park & Gelles-Watnick, 2023). A recent report by the UK's Department for Education indicated that early years and childcare providers in the UK are not yet using GAI (Department for Education, 2023). A recent literature review suggests that most of the attention is paid to later stages of education rather than ECE (Bahroun et al., 2023).

There will also be a need to assess how exactly GAI is being used and integrated in practitioners' ways of working. Research trialling LLMs in real-world work tasks suggest that it can increase the quality of outputs for certain writing tasks (Noy & Zhang, 2023), but there is also a risk that users rely on GAI too much in cases where LLMs are not yet sufficiently proficient. Research involving analysts at the Boston Consulting Group showed that people working with GAI might “fall asleep at the wheel” and become less skilled in their own judgement (Dell'Acqua et al., 2023). Therefore, it will be important to develop best practice guidelines and training, and ensure that GAI does not lead to de-professionalization.

5 CONCLUSION: IMAGINING A TRANSFORMATIVE CHANGE
GAI has the potential to impact many different aspects of early childhood development and education. Like past general purpose technologies such as electricity, GAI presents a chance to fundamentally rethink our ways of working. We encourage psychology and educational researchers to work with practitioners, futurists and engineers to collaboratively envision transformative, positive changes in our disciplines.